# [Generative Adversarial Nets](https://papers.nips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf)

## Abstract

我们提出一种通过对抗性过程来估计生成式模型的新框架，我们同时训练两个模型：一个捕获数据分布的生成式模型 $G$，和一个估计样本是来自训练数据而不是 $G$ 的概率的判别式模型 $D$。$G$ 的训练过程是最大化 $D$ 犯错的概率。这个框架对应于一个极大极小的双人博弈。在任意函数 $G$ 和 $D$ 的空间中，存在一个唯一解，使得 $G$ 可以恢复训练数据的分布，且 $D$ 处处等于 $\frac{1}{2}$。在 $G$ 和 $D$ 是由多层感知机定义的情况下，整个系统可以使用反向传播进行训练。在整个训练和样本生成过程中，不需要任何的马尔可夫链或者展开近似的推理网络。实验通过对生成的样本的定性和定量评估，证明了该框架的潜力。

## 1 Introduction

深度学习的承诺 (promise) 是发现丰富的、有层次的模型 [2]，这些模型表示人工智能应用中遇到的各种数据的概率分布，比如自然图像、包含语音的音频波形和自然语言语料库中的符号。到目前为止，深度学习中最惊人的成功已经涉及到判别式模型，这些模型通常将一个高维的、富有感官的输入映射到一个类别标签。这些惊人的成功主要是基于反向传播和 dropout 算法，使用具有特别好梯度的分段线性单元。由于在最大似然估计和相关策略中的许多难以近似的棘手的概率计算，以及在生成环境中难以利用分段线性单元的好处，深度生成式模型的影响较小。我们提出一种新的生成式模型估计程序来避开这些困难。

在提出的对抗网络框架中，生成式模型是与一个对手对抗的：一个判别式模型，它学习判定一个样本是来自模型分布还是数据分布。生成式模型可以被认为是一个造假的团队，试图产生假的假币并使用它而不被发现，而判别式模型类似警察，试图发现假币。这场比赛的竞争促使两支队伍改进它们的方法，直到仿冒品与真品难以区分。

**ps：** 最终希望生成式模型能胜过判别式模型，然后能生成与真实分布一致的数据。

这个框架可以为多种模型和优化算法提供特定的训练算法。在本文中，我们探讨了当生成式模型通过将一个随机噪声传递给一个多层感知机来生成样本，并且判别式模型同样是一个多层感知机的特殊情况。我们把这种特殊情况称为对抗网络。在这种情况下，我们可以只使用非常成功的反向传播和 dropout 算法训练两个模型，并只使用前向传播从生成式模型中采样。不需要近似推理或者马尔可夫链。

## 2 Related work

直到最近，大多数关于深度生成式模型都集中在为概率分布函数提供参数规范的模型上。然后可以通过最大化对数似然来训练模型。在这一系列模型中，也许最成功的是深度玻尔兹曼机。这类模型通常具有难以处理的似然函数，因此需要对似然梯度进行无数次近似。这些困难推动了 "生成式机器"——模型不显式地表示似然，但能从期望的分布中生成样本。生成随机网络是生成式机器的一个例子，它可以用精确的反向传播来训练，而不是玻尔兹曼机器所需的无数次近似。这项工作通过消除生成随机网络中使用的马尔可夫链，扩展了生成式机器的思想。

我们的工作通过使用以下的观察将梯度反向传播给生成过程：
$$
\large \lim_{\sigma \rightarrow 0} \nabla_x \mathbb{E}_{\epsilon \sim \mathcal{N}(0,\sigma^2 \boldsymbol{I})} f(\boldsymbol{x} + \epsilon) = \nabla_x f(\boldsymbol{x})
$$
在我们开展这项工作时，我们不知道 Kingma 和 Welling [18] 和 Rezende 等人 [23] 已经研究出了更通用的随机反向传播规则，允许模型通过具有有限方差的高斯分布来反向传播，并反向传播到协方差参数和均值。这些反向传播规则可以让模型学习生成器的条件方差，我们在本工作中把它当作超参数。Kingma 和 Welling 和 Rezende 等人使用随机反向传播训练变分自编码器 (VAEs)。像生成式对抗网络一样，变分自编码器将一个可微分生成器网络与第二个神经网络配对。不像生成式对抗网络，VAE 中的第二个神经网络是一个执行近似推理的识别模型。GANs 需要通过可视单元进行微分，因此不能对离散数据进行建模，而 VAEs 需要通过隐藏单元进行微分，因此不能有离散的潜在变量。存在着其他的 [12, 22] 类似 VAE 的方法，但与我们的方法的关系不太密切。

先前的工作 [29,13] 也采用了使用一个判别式准测来训练一个生成式模型的方法。这些方法使用的准则是深度生成式模型难以处理的。深度模型甚至很难近似这些方法，因为它们涉及到概率的比率，不能用降低概率边界的变分近似来近似。噪声对比估计 (NCE) 涉及通过学习使模型在从固定噪声分布中区分数据有用的权重来训练生成式模型。使用先前训练过的模型作为噪声分布，可以训练一系列质量不断提高的模型。这可以被视为一种非正式的竞争机制，在精神上类似于对抗性网络游戏中使用的正式的竞争。NCE 的关键限制是它的 "鉴别器" 是由噪声分布和模型分布的概率密度的比率来定义的，因此需要评估和反向传播两个密度的能力。

先前的一些工作使用了一般意义上的两个神经网络对抗的概念。最相关的工作是可预测性最小化。在可预测性最小化中，神经网络中的每个隐藏单元都被训练成不同于第二个网络的输出，第二个网络是在给定其他隐藏层神经元的值的情况下预测那个隐藏层神经元的值。本项工作在三个重要方面不同于可预测性最小化：1) 在这项工作中，网络之间的竞争是唯一的训练准则，它本身足以支撑训练网络。可预测性最小化仅是一个正则器，它促进网络中的隐藏单元在完成其他任务时保持统计上的独立性；这不是首要的训练准则。2) 竞争的本质不同。在可预测性最小化中，两个网络的输出进行比较，其中一个网络试图使两个网络的输出相似，而另外一个网络试图使两个网络的输出不同。所讨论的输出是一个标量。在 GANs 中，一个网络产生一个多样的、高维的向量作为另外一个网络的输入，并试图选择一个使另外一个网络不知道如何处理的输入。3) 学习过程的规范不同。可预测性最小化被描述为一个最小化目标函数的优化问题，并学习逼近目标函数的最小值。GANs 是基于极大极小博弈而不是优化问题的，它有一个价值函数，一个 agent 寻求最大化，而另外一个寻求最小化。博弈终止于一个鞍点，这个鞍点对于一方的策略是最小值，对于另一方的策略是最大值。

生成式对抗网络有时会与 "对抗样本" 这个概念混淆。对抗样本是指直接在分类网络的输入上使用基于梯度的优化找到的样本，以便找到与数据相似但被错误分类的样本。这与当前的工作不同，因为对抗样本不是一种用于训练一个生成式模型的机制。相反，对抗样本主要是一种分析工具，以有趣的方式展示神经网络行为，经常自信地以高置信度对两张图像进行不同分类，即使它们之间的差异对于人类观察者来说是难以察觉的。这种对抗样本的存在表明生成式对抗网络的训练可能是低效的，因为它们表明现代判别式模型在不模拟任何人类可感知的类别属性时，就能自信地识别出类别。

## 3 Adversarial nets

对抗建模框架的最简单的应用是当生成器和鉴别器都是多层感知机。为了学到生成器在数据 $x$ 上的分布 $p_g$，我们在输入噪音变量 $p_z(z)$ 上定义了一个先验，然后将到数据空间的映射表示为 $G(z;\theta_g)$，其中 $G$ 是一个由参数为 $\theta_G$ 的多层感知机表示的一个可微分的函数。我们还定义了第二个多层感知机 $D(x;\theta_d)$，输出一个标量。$D(x)$ 表示 $x$ 是来自数据还是 $p_g$ 的概率。我们训练 $D$ 来最大化将正确的标签分配给训练样本和 $G$ 中的样本的概率。我们同时训练 $G$ 来最小化 $\log(1 - D(G(z)))$。换句话说，$D$ 和 $G$ 用下列价值函数进行双人极大极小博弈：
$$
\large \min_G \max_D V(D,G) = \mathbb{E}_{x \sim p_{data}} \left [ \log(D(\boldsymbol{x})) \right ] + \mathbb{E}_{z \sim p_z(z)} \left [ \log(1 - D(G(z))) \right ]. \tag{1}
$$
在下一节中，我们将提出对抗性网络的理论分析，本质上表明当 $G$ 和 $D$ 被给予足够多的容量时 (即无参数限制)，训练准则足以让生成器恢复出数据的生成分布。参阅图 1 以获得对该方法不那么正式，但更具教学意义的解释。实际上，我们必须使用迭代式的数值方法来实现这样的博弈。在训练中的内循环中优化 $D$ 到最优是很高计算成本的，并且在有限的数据集上会导致过拟合。相反，我们交替进行 $D$ 优化 $k$ 步和 $G$ 优化一步。只要 $G$ 的变化足够满，这会使得 $D$ 保持在它的最优解的附近。程序在算法 1 中正式给出。

实际上，等式 1 可能无法提供足够的梯度让 $G$ 学习得好。学习的早期阶段，当 $G$ 较差时，$D$ 能够以高置信度拒绝来自 $G$ 的样本，因为它们明显与训练数据不同。这种情况下，$\log(1 - D(G(z)))$ 进入饱和。与其训练 $G$ 来最小化 $\log(1 - D(G(z)))$，我们可以训练 $G$ 来最大化 $\log(D(G(z)))$。这个目标函数导致 $G$ 和 $D$ 的最终收敛的点不变，但是可以在模型学习的早期阶段提供更强的梯度。

## 4 Theoretical Results

生成器 $G$ 隐式地定义了一个概率分布 $p_g$ 作为当 $z \sim p_z$ 时由 $G(z)$ 得到的样本的分布。因此，如果给定足够的容量和训练时间，我们希望算法 1 能够收敛到 $p_{data}$ 的一个好的估计量。本节的结果是在一个非参数的设置下完成的，例如，我们通过研究概率密度函数空间中的收敛性来表示具有无限容量的模型。

我们将在 4.1 节中展示极大极小博弈对于 $p_g = p_{data}$ 有一个全局最优解。我们将在 4.2 节中展示用算法 1 优化等式 1，从而获得想要的结果。

<img src="assets/GAN_fig1.png" title="图1">

**图 1：** 通过同时更新鉴别分布 (D，蓝色虚线) 来训练生成式对抗网络，使 $D$ 区分样本是来自数据的生成分布 (黑色虚线) $p_x$，还是来自生成式分布 $p_g$ (绿色实线)。下面的水平线是 $z$ 采样的域，在本例中是均匀分布。上面的水平线        是 $x$ 的域的一部分。向上的箭头表示映射 $\boldsymbol{x} = G(z)$ 是如何对变换后的样本施加非均匀分布 $p_g$ 的。(a) 考虑一个接近收敛的对抗性对：$p_g$ 与 $p_{data}$ 相似，而 $D$ 是一个部分准确的分类器。(b) 在算法的内循环中，$D$ 被训练来从数据中区分 (生成) 样本，收敛于 $D^*(\boldsymbol{x}) = \frac{p_{data}(x)}{p_{data}(x) + p_g(x)}$。(c) 更新 $G$ 之后，$D$ 的梯度引导 $G(z)$ 流向更有可能被分类为数据的区域。(d) 经过多个 steps 训练后，如果 $G$ 和 $D$ 有足够的容量，它们会达到一个双方都无法继续提升的点，因为 $p_g = p_{data}$ 。鉴别器无法区分两个分布，即 $D(\boldsymbol{x}) = \frac{1}{2}$。



<hr style="height:1px;border:none;border-top:2px solid #555555;" />







REFERENCE:

https://rdc.hundsun.com/portal/article/920.html
