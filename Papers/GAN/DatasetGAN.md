# [DatasetGAN: Efficient Labeled Data Factory with Minimal Human Effort](https://arxiv.org/pdf/2104.06490.pdf)

## Abstract

我们介绍 DatasetGAN：一个只需要极少的人力就能自动生成大量高质量的语义分割图像数据集的程序。目前的深度网络都是极其数据饥渴的，并受益于在大规模的数据上的训练，而对这些数据集进行标注是非常耗时的。我们的方法依赖最近的 GANs 的能力来生成真实的图像。我们展示了 GAN 的潜在编码可以被解码，以产生一幅图像的语言分割。训练这个解码器只需要少量标注的样本，就可以泛化到其余的潜在空间，从而产生一个无限的带标注的数据生成器！这些生成的数据集可以被用来训练任意的计算机视觉架构，就像一个真实的数据集一样。由于只有少量图像需要手动分割，因此可以对图像进行非常详细的标注，并生成具有丰富的对象和某些部分的分割数据集。为了展示我们的方法的能力，我们为 7 个图像分割任务生成了数据集，其中包含 34 个人脸部件和 32 个汽车部件的像素级标签。我们的方法明显优于所有的半监督基线，并与全监督方法相当，在某些情况下，全监督方法需要比我们的方法多 100 倍的标注数据。

## 1. Introduction

使用语义或者实例分割等像素级标签来管理图像数据集是非常费力 (且昂贵) 的。标注一个有 50 个物体的复杂场景可能需要花费 30 - 90 分钟，这显然是实现我们可能想要的数据集规模的瓶颈。在本论文中，我们的目标是通过只标注少量的样本来合成大型高质量的已标注的数据集。

半监督学习通过利用额外的大量未标注的数据集，已经成为减少对标注数据的需求的探索中的一种流行的方法。主流方法是在一个使用真实标注的已标注数据集上训练一个模型，同时在未标注的样本上使用伪标签 [3,47] 和一致性正则化。虽然大多数方法都被用于分类任务，但最近的工作也展示了在语义分割任务上的成功。另一方面，对比学习的目标是利用在采样图像对，或者图像块的对比 (无监督) 损失来训练特征提取器。一旦通过单一的无监督损失训练出一个强大的图像表示，通常只需要一小部分已标注图像来训练准确的预测器。在我们的工作中，我们展示了最新的最先进的图像生成模型，学习极其强大的潜在表示，能被用于复杂的像素级任务。

我们引入了 $DatasetGAN$，它可以生成大量高质量的语义分割图像数据集而只需要最低限度的人力。我们的方法的关键是观察到，GANs 训练合成图像必须获得丰富的语义知识，以呈现各式各样的且真实的物体的示例。我们利用一个训练过的 GAN 的特征空间，并训练一个浅的解码器来产生像素级的标注。我们的关键见解是，只需要少量的已标注数据就可以训练一个成功的解码器，从而产生无限的标注的数据集生成器。这些生成的数据集能被用于训练任何计算机视觉架构，就像真正的数据集一样。因为我们只需要标注少量的样本，我们可以非常详细地标注图像，并生成具有丰富对象和部分分割的数据集。我们生成了 7 个分割任务的数据集，其中包括 34 个人脸部件、32  个汽车部件的像素级标注。我们的方法明显优于所有的半监督基线，并且与完全监督的方法持平，但在某些情况下需要的标注数据少两个数量级。

## 2. Related Work

**标注数据的生成模型：** 先前关于数据集合成的研究主要集中于 3D 场景图的生成模型，利用图形学来渲染图像及其标签。在我们的工作中，我们关注于生成对抗网络 (GANs)，它在使用对抗样本的大数据集上训练后，合成高质量的图像。先前的工作利用 GANs 来创建合成的数据集。在域适应中，一些工作旨在通过利用图像到图像的转换技术，将标记好的图像数据集转换到另外一个域，在这个域中，图像标注要么昂贵，要么完全缺失。然后可以在转换后的数据集上训练一个有监督的计算机视觉模型。这些方法假设存在一个大型的已标注的域，可以被用于新的域。在我们的工作中，我们只需要少量人工标注的图像，就可以合成一个更大的集合。

最近，[55] 使用 StyleGAN 作为多视图图像数据集生成器，用于训练一个逆向图网络来预测 3D 形状。作者利用了在 StyleGAN 的潜在编码中视图与物体身份之间的解耦合。我们更进一步，仅利用人类提供的一些样本来合成准确的语义标签。为了实现零样本图像分类，GANs 也被用于从未见过的类的语义特征中合成未见过的类的可视化特征。据我们所知，我们的工作是第一个使用 GANs 来直接合成有高水平的细节标注的大型图像数据集的。

**半监督学习：** 给定一批大量未标注的图像和一批少量已标注的图像，半监督方法的目的是学习比单独使用监督数据更好的分割网络。这些方法大多数将分割网络当作生成器，并使用少量真正的标注对抗训练。在他们的案例中，对抗性损失试图从模型产生的虚假的分割中学习到好的分割，但他们不像我们那样利用图像本身的生成性建模。伪标签和一致性正则化最近也被探索用于语义分割，其中关键思想是在小型的已标注的数据集上训练，并使用真实标注数据与对未标注图像的高置信度的预测的混合再重新训练模型。不同于现有的半监督方法，我们利用一个 GAN 来合成图像及其像素级标签。

同一时刻的工作 [15] 也将 GAN 的特征转换为语义分割。然而，他们的方法依赖于用卷积和残差块构建的解码器，用于将 StyleGAN 的内部层投影到分割映射上。我们的方法直接通过一个简单的 MLP 分类器的集成，将每个像素的解纠缠的特征向量直接解释为其语义标签，这更好地利用了 StyleGAN 特征向量中的语义知识。此外，我们使用我们的方法创建带有高细节的部分标签和关键点注释的大型图像数据集，我们希望这将使以前不可能实现的各种下游应用成为可能。

同一时刻的工作 [32]，作者探索了另外一个方向，GAN 配备分割分支，也被用作测试时的语义解码器。[35] 中探索了一个相关的想法，使用 VAE 从部分可见的 masks 解码非模态的实例 masks。编码器使用测试时优化将图像映射到潜在编码，然后使用该编码来预测重建图像和语义输出。语义 GAN 的训练和我们不同，使用对抗性损失。该方法比我们的方法需要更多的训练数据，并且测试时更慢，然而，它有能泛化到域之外的优点。

**对比学习：** 对比方法使用一个对比性损失来测量采样对的相似性来学习一个图像的表示空间。最近关于对比学习的研究已经在图像分类上展现出不错的结果。利用学习后的自监督表示，通过在少量已标注的样本上微调，能够显著地提升分类的准确性。通过在成对的图像块上学习，对比学习也可以被应用于图像分割。像我们一样，这一系列的工作使用学习后的图像表示来分摊对于大型标注数据集的需求。但是，我们没有使用对比性损失，而是利用了 GAN 的特征图中的语义知识来进行细粒度的注释合成。

## 3. Our Approach

我们现在介绍合成图像-标注对的 $\rm D{\scriptsize ATASET}GAN$。我们主要关注像素级标注任务，比如语义分割和关键点预测，因为它们是最耗时的人工标注任务中的典型例子。

$\rm D{\scriptsize ATASET}GAN$ 的关键见解是生成模型，比如 GANs，在被训练用来合成高度真实的图像时，必须在其高维的潜在空间中获取语义知识。例如，像 StyleGAN 这样的架构中的潜在编码包含了控制诸如视角和物体身份等 3D 属性的解耦合的维度。在两个潜在编码之间的插值已经被证明能产生逼真的生成，这表明 GAN 也学到了语义上和几何上对齐物体及它们的部分。$\rm D{\scriptsize ATASET}GAN$ 的目的是利用图像 GANs 的这些强大的特性。直观地说，如果一个人提供了一个对应于一个潜在编码的标签，我们期望能够跨越 GAN 的潜在空间有效地传播这个标签。

我们的 $\rm D{\scriptsize ATASET}GAN$ 十分简单，但非常强大。具体来说，我们利用一个 GAN 架构来合成少量的图像，本文中是 StyleGAN，并记录它们对应的潜在特征图。一个人类标注者被要求为这些图像打上一组所需要的标签。然后我们在 StyleGAN 的逐像素的特征向量上训练一个简单的 MLP 分类器的集成，我们将其称为风格解释器，来匹配人类提供的目标标签。图 2 提供了一个可视化。我们观察到，训练风格解释器仅需要少量的带标注的样本就能取得不错的精度。在训练风格解释器时，我们将其用作 StyleGAN 架构中的一个标签生成分支。通过采样潜在编码 $z$，并将其传递通过整个架构，我们得到了一个无限的数据集生成器！这些数据集能像真实数据集一样被用于训练任意的计算机视觉架构。

我们利用 $\rm D{\scriptsize ATASET}GAN$ 的仅需要少量人工标注的图像的效率优势，并致力于将每个独立图像标注为非常多细节的像素级标签。我们创建了有 40 张图像的微小数据集，包含了非常详细的部分和少数类别的关键点的标注，并利用我们的 $\rm D{\scriptsize ATASET}GAN$ 来合成更大的数据集。我们相信社区将会发现这些数据集对各种令人兴奋的下游应用有用。

我们在 3.1 节中简要地总结了 StyleGAN，并在 3.2 节中描述风格解释器。我们在 3.3 节中讨论数据集生成，并在第 4 节中详细介绍我们的标注成果。

### 3.1. Prerequisites

由于StyleGAN 的令人印象深刻的合成质量，$\rm D{\scriptsize ATASET}GAN$ 使用它作为生成主干。StyleGAN 生成器将从正态分布中抽取的潜在编码 $z \in Z$ 映射到真实的图像。潜在编码 $z$ 首先通过一个映射函数被映射到中间潜在编码 $w \in W$。然后 $w$ 被转换为 $k$ 个向量，$w^1,\dots,w^k$，得到 $k$ 个学习后的仿射变换。这些 $k$ 个变换后的潜在编码以渐进的方式作为风格信息被注入到 $k/2$ 个合成块中。具体来说，每个合成块有一个上采样 ($\times 2$) 层和两个卷积层组成。





## 6. Conclusions

我们提出了一种简单但强大的方法，用于使用少量标注的半监督学习。我们利用了最先进的生成模型 StyleGAN 的学习过的潜在空间，并证明可以在少量的人类标注的图像上训练有效的分类器。我们手动标注了对应 7 个不同任务的极小数据集，每个都很多细节 (标签多)。在这些上面训练，我们的 $\rm D{\scriptsize ATASET}GAN$ 合成了大型已标注的数据集，可以被用于训练计算机视觉架构 (模型?)。我们的方法被证明明显优于所有的半监督基线，在某些情况下超过使用多于两个数量级以上数据的完全监督的方法。我们相信这只是向更有效地训练深度网络的迈出的第一步。在未来，我们计划扩展 DatasetGAN 来处理大型并多样的类集。
