# [Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation](https://arxiv.org/pdf/1802.02611.pdf)

## Abstract

深度神经网络采用空间金字塔汇聚模块或编码器—解码器结构完成语义分割任务。前者能够编码多尺度的上下文信息，通过使用滤波器探测即将到来的特征，或在多种比率和多种有效感受野的汇聚操作，而后者可以通过逐步恢复空间信息来捕获更锐利的物体边界。在这项工作中，我们提出结合两种方法的优点。具体来说，我们提出的模型，DeepLabv3+，通过添加一个简单而有效的编码器模块来扩展 DeepLabv3，以精炼分割结果，特别是沿着物体边界的结果。我们进一步探索了 Xception模型，并将深度可分离卷积应用到空洞空间金字塔汇聚和解码器模块，从而得到更快和更强的编码器—解码器网络。我们在 PASCAL VOC 2012 和 Cityscapes 数据集上证明了所提出的模型的有效性，在不进行任何后处理的情况下，测试集性能达到 89.0% 和 82.1%。我们的论文附带了一个所提出模型在 TensorFlow 上公开可用的参考实现：https://github.com/tensorflow/models/tree/master/research/deeplab

## 1 Introduction

语义分割的目标是为图像中的每个像素分配语义标签，是计算机视觉的基本课题之一。在基准任务上，基于完全卷积神经网络的深度卷积神经网络比依赖手工制作的特征的系统有显著的改进。在这项工作中，我们考虑两种类型的神经网络，它们使用空间金字塔汇聚模块或者编码器—解码器结构来进行语义分割，其中前者通过汇聚不同分辨率的特征来捕获丰富的上下文信息，而后者能够获得锐利的物体边界。

为了在多个尺度上捕获上下文信息，DeepLabv3 应用了多个并行的、不同 atrous rate 的空洞卷积 (称为空洞卷积金字塔汇聚，或 ASPP)，而 PSPNet 在不同的网格尺度上执行汇聚操作。尽管在最后一个特征映射中编码了丰富的语义信息，但由于网络骨干中的汇聚或者带有跨步操作的卷积，与物体边界相关的详细信息丢失。通过应用空洞卷积提取更密集的特征映射可用缓解这一问题。然而，考虑到最先进的神经网络的设计和有限的 GPU 内存，在计算上无法提取比输入分辨率小 8 倍，甚至小 4 倍的输出特征映射。以 ResNet-101 为例，当应用空洞卷积提取比输入分辨率小 16 倍的输出特征时，最后 3 个残差块 (9 层) 内的特征会被扩大。更糟糕的是，如果期望输出特征的分辨率比输入小 8 倍，那么 26 个残差块 (76 层) 将受到影响。因此，如果为这种类型的模型提取更密集的输出特征，它的计算量很大。另一方面，编码器—解码器模型可用在编码器路径上进行更快的计算 (因为没有特征被扩大)，并在解码器路径上逐渐恢复尖锐的物体边界。试图结合这两种方法的优点，我们提出通过合并多尺度的上下文信息来丰富编码器—解码器网络中的解码器模块。

特别地，我们提出的模型，称为 DeepLabv3+，通过添加一个简单但有效的解码器模块来恢复物体的边界来扩展 DeepLabv3，如图 1 所示。丰富的语义信息被编码到 DeepLabv3 的输出中，通过空洞卷积允许人们根据计算资源的预算来控制编码器特征的密度。此外，解码器模块使精细的物体边界的恢复成为可能。

受最近成功的深度可分离卷积的激励，我们也探索了这种操作，并通过采用类似于 [31] 的 Xception [26] 来完成语义分割任务，并将空洞可分离卷积应用到 ASPP 和解码器模块，在速度和准确性方面都有所提升。最后，我们在 PASCAL VOC 2012 和 Cityscapes 数据集上证明了所提出的模型的有效性，在没有任何后处理的情况下，获得了 89.0% 和 82.1% 的测试集性能，创下了一个新的最先进水平。

总而言之，我们的贡献是：

- 我们提出了一种新颖的编码器—解码器结构，采用 DeepLabv3 作为一个强大的解码器模块和一个简单但有效的解码器模块。
- 在我们模型结构中，可以**通过空洞卷积来任意控制提取到的编码器的特征的分辨率**，以权衡精度和运行时间，这是现有的编码器—解码器模型所不能的。
- 我们将 Xception 模型用于分割任务，并将深度可分离卷积应用到 ASPP 模块和解码器模块，从而产生更快和更强的编码器—解码器网络。
- 我们所提出的模型在 PASCAL VOC 2012 和 Cityscapes 数据集上获得了一个新的最先进的性能。我们还提供了设计选型和模型变体的详细分析。
- 我们在 https://github.com/tensorflow/models/tree/master/research/deeplab 上公开了所提出的模型基于 TensorFlow 的实现。

<img src="assets/DeepLabv3Plus_fig1.png" title="图1">

**图 1：** 我们使用编码器—解码器结构 (b) 改进了采用空间金字塔汇聚模块 (a) 的 DeepLabv3。所提出的模型，DeepLabv3+，包含了来自解码器模块的丰富的语义信息，而精细的物体的边界由简单但有效的解码器模块恢复。通过采用空洞卷积，解码器模块允许我们提取任意分辨率的特征。

## 2 Related Work

基于完全卷积神经网络 (FCNs) 的模型已经在几个分割基准上展示出了显著的改进。为了利用上下文信息分割，人们一些模型变体，包括采用多尺度输入 (即图像金字塔) 或采用概率图形模型 (如带有高效推理算法的 DenseCRF)。在本工作中，我们主要讨论使用空间金字塔汇聚和编码器—解码器结构的模型。

**空间金字塔汇聚：** 如 PSPNet 或者 DeepLab 这类模型，在多个网格尺度上执行空间金字塔汇聚 (包括图像级的汇聚) 或者应用多个并行的、不同 rate 的空洞卷积 (被称为 空洞空间金字塔汇聚，或者 ASPP)。这些模型通过利用多尺度的信息在多个分割基准上展现出了有希望的结果。

**编码器—解码器：** 编码器—解码器网络已经被成功地应用到许多计算机视觉任务，包括人体姿态估计、目标检测和语义分割。通常，编码器—解码器网络包含 (1) 一个逐渐降低特征映射和捕获更高级语义信息的编码器模块和 (2) 一个逐渐恢复空间信息的解码器模块。在此基础上，我们提出使用 DeepLabv3 作为编码器模块，并添加一个简单但有效的解码器模块来获得更锐利的分割。

**深度可分离卷积：** 深度可分离卷积或分组卷积，一种强大的操作，可用减少计算成本和参数数量并同时保持相似 (或略好) 的性能。这种操作已经在许多最近的网络设计中被采用。特别地，我们探索了与用于 COCO 2017 检测挑战提交的 [31] 相似的 Xception 模型，并在语义分割任务的准确性和速度方面都有所提升。

## 3 Methods

在本节中，我们简单地介绍了空洞卷积核深度可分离卷积。然后在讨论所提出的添加到解码器输出后的编码器模块之前，我们先回顾被用作我们的编码器模块的 DeepLabv3。我们还提出了一个改进的 Xception 模型，它进一步提升了性能，计算更快。

<img src="assets/DeepLabv3Plus_fig2.png" title="图2">

**图 2：** 我们提出的 DeepLabv3+ 通过使用一个编码器—解码器结构扩展了 DeepLabv3。解码器模块通过在多尺度上应用空洞卷积对多尺度的上下文信息进行编码，而简单但有效的解码器模块细化沿着物体边界的分割结果。

### 3.1 Encoder-Decoder with Atrous Convolution

**空洞卷积：** 空洞卷积推广了标准的卷积运算，是一种强大的工具，允许我们显式地控制深度卷积神经网络计算的特征的分辨率，并调整滤波器的感受野以捕获多尺度的信息。在二维信号的情况下，对于输出特征映射 $\boldsymbol{y}$ 每个位置 $i$ 和一个卷积滤波器 $\boldsymbol{w}$，空洞卷积以下列形式应用于输入特征映射 $\boldsymbol{x}$ 上：
$$
\large \boldsymbol{y}[i] = \sum_k \boldsymbol{x}[i + r \cdot k] \boldsymbol{w}[k] \tag{1}
$$

其中空洞率 $r$ 决定了我们对输入信号的采样步长。我们建议有兴趣的读者参考 [39] 以了解更多的细节。注意到标准卷积是一种空洞率 $r = 1$ 的特殊情况。通过改变空洞率 $r$，对滤波器的感受野进行自适应地调整。

**深度可分离卷积：** 深度可分离卷积，将一个标准卷积分解为一个深度卷积，后面跟着逐点的卷积 (即 $1 \times 1$ 的卷积)，极大地减少计算复杂度。具体而言，深度卷积在每个通道独立地执行一次空间卷积，而逐点的卷积被用于合并深度卷积的输出。在 TensorFlow 的深度可分离卷积的实现中，空洞卷积已经在深度卷积 (即空间卷积) 中得到支持，如图 3 所示。在本工作中，我们将得到的卷积称为 *空洞可分离卷积*，并发现空洞可分离卷积在保持相似 (或更好) 性能的同时，显著地降低了所提出的模型的计算复杂度。

**DeepLabv3 作为编码器：** DeepLabv3 采用空洞卷积来提取任意分辨率的深度卷积网络计算得到的特征。这里，我们将 $output \ stride$ 表示为输入图像的空间分辨率与最终输出分辨率 (全局汇聚或者全连接层之前) 的比值。对于图像分类任务，最终特征映射的空间分辨率通常比输入图像的分辨率小 32 倍，因此 $output \ stride = 32$。对于语义分割任务，可以采用 $output \ stride = 16$ 或者 8 来进行更密集的特征提取，通过移除最后一 (或两) 个块中的跨步，并相应地应用空洞卷积 (例如，对于 $output \ stride = 8$，我们分别对最后两个块应用 $rate = 2$ 和 $rate = 4$)。此外，DeepLabv3 以图像级特征增强了空洞空间金字塔汇聚模块，它通过应用不同空洞率的空洞卷积在多个尺度上探测卷积的特征。我们使用原始的 DeepLabv3 的 logits 之前的最后一个特征映射作为我们所提出的编码器—解码器结构中的编码器的输出。请注意编码器的输出特征映射包含 256 个通道和丰富的语义信息。此外，通过应用空洞卷积，可以提取任意分辨率的特征，特征的分辨率取决于计算预算。

**所提出的编码器：** DeepLabv3 的编码器 (输出的) 特征通常以 $output \ stride = 16$ 来计算。在 [23] 的工作中，特征被 16 倍双线性上采样，这可以被认为是一个朴素的 (naive) 解码器模块。

## 5 Conclusion

我们所提出的模型 "DeepLabv3+" 采用编码器—解码器结构，其中 DeepLabv3 被用于编码丰富的上下文信息，而一个简单但有效解码器模块被使用来恢复物体的边界。人们可以通过采用空洞卷积来提取任意分辨率的编码器特征，特征的分辨率取决于可用的计算资源。我们还探索了 Xception 模型和空洞可分离卷积，使所提出的模型更快和更强。最后，我们的实验结果表明，所提出的模型在 PASCAL VOC 2012 和 Cityscapes 数据集上建立了一个新的最先进的性能。
