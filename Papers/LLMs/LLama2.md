# [LLAMA 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288)

## Abstract

这项研究中，我们开发并发布了 Llama 2，这是一个包含预训练和微调的大型语言模型 (LLM) 系列，参数规模从 70 亿到 700 亿不等。我们称之为 LLAMA 2-CHAT 的微调的 LLM 专门为对话用例进行了优化。在测试的大多数基准测试中，我们的模型均优于开源聊天模型，并且根据我们针对帮助性和安全性进行的人工评估，它可能可以替代闭源模型。为了使社区能够利用我们的工作并为负责任地开发大型语言模型做出贡献，我们详细描述了用于微调 LLAMA 2-CHAT 和提高其安全性的方法。

## 1 Introduction

大型语言模型 (LLM) 在担任功能强大的 AI 助手方面展现了巨大潜力，擅长于需要跨越广泛领域（包括编程和创意写作等专业领域）的专家知识的复杂推理任务。它们通过直观的聊天界面实现与人类的互动，在普通大众中被快速且广泛的采用。

LLM（Language Model，语言模型）的能力令人瞩目，尽管其训练方法看似简单。自回归变换器首先在大规模的自监督数据上进行预训练，然后通过诸如“人类反馈强化学习”（RLHF）等技术与人类偏好进行对齐。尽管训练方法简单，高昂的计算需求却将 LLM 的发展限制在了少数参与者手中。一些开放预训练的 LLM（例如 BLOOM (Scao 等人，2022)、LLaMa-1 (Touvron 等人，2023) 和 Falcon (Penedo 等人，2023)）已经发布，其性能可以媲美 GPT-3 (Brown 等人， 2020) 和 Chinchilla (Hoffmann 等人，2022) 等闭源的预训练的竞争对手。然而，这些开放模型都不能完全替代诸如 ChatGPT、BARD 和 Claude 等闭源的“产品” LLM。这些闭源产品LLM经过了严格的微调，以与人类偏好保持一致，从而大大提高了它们的可用性和安全性。此步骤通常需要大量计算资源和人工标注，并且透明度和可复制性往往较低，限制了社区在推进人工智能目标一致性研究方面的进展。

在这项工作中，我们开发并发布了 Llama 2 系列预训练和微调 LLM，包括 Llama 2 和 Llama 2-Chat，参数规模最高可达 700 亿。在测试的一系列帮助性和安全性基准测试中，Llama 2-Chat 模型通常表现优于现有的开源模型。它们似乎也与一些封闭源代码模型不相上下，至少在我们进行的人工评估中是这样 (见图 1 和图 3)。我们通过使用特定于安全的数据注释和调整，以及进行红队测试和迭代评估来提高这些模型的安全性。此外，本文还详细描述了我们用于微调 LLM 和提高其安全性的方法。我们希望这种开放性可以让社区能够复制微调后的 LLM 并继续提高这些模型的安全性，为更负责任地开发 LLM 铺平道路。我们还分享了我们在开发 Llama 2 和 Llama 2-Chat 过程中的一些新颖发现，例如工具使用的出现和知识的时序组织。

我们将以下模型向公众发布，用于研究和商业用途‡:

1. Llama 2，这是 Llama 1 的更新版本，使用来自公共数据集的新混合数据进行训练。我们还将预训练语料库的规模增加了 40%，将模型的上下文长度增加了一倍，并采用了分组查询注意力 (Ainslie 等人，2023)。我们将发布具有 7B、13B 和 70B 参数的 Llama 2 变体。我们还训练了 34B 的变体，我们在本文中进行了报告，但不会发布.§
2. Llama 2-Chat，它是 Llama 2 的微调版本，专为对话用例进行了优化。我们也发布了具有 7B、13B 和 70B 参数的此模型变体。我们相信，在安全的情况下开放大型语言模型将对社会产生净收益。与所有大型语言模型一样，Llama 2 也是一项新技术，其使用可能会带来潜在风险 (Bender 等人，2021b; Weidinger 等人，2021; Solaiman 等人，2023)。迄今为止进行的测试都是使用英语进行的，并未涵盖所有场景，也无法涵盖所有场景。因此，在部署任何 Llama 2-Chat 应用之前，开发人员应针对其特定模型应用进行安全测试和调整。我们提供了负责任使用指南¶ 和代码示例‖，以促进 Llama 2 和 Llama 2-Chat 的安全部署。有关我们负责任发布策略的更多详细信息，请参见第 5.3 节





