# [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)

## ABSTRACT

本文中，我们研究了卷积网络深度对其在大规模图像识别任务中的准确性的影响。我们的主要贡献是通过使用一种非常小 $(3 \times 3)$ 的卷积过滤器的架构对网络深度的增加进行了全面评估，结果显示通过将深度提升到 16-19 个权重层，可以实现对现有技术配置的显著改进。这些发现是我们在 2014 年 ImageNet 挑战赛提交的基础，在该比赛中，我们的团队分别在定位和分类赛道上获得了第一名和第二名。我们还展示了我们的表征能很好地推广到其他数据集，在这些数据集上我们也取得了最先进的结果。我们已经公开发布了我们的两个性能最佳的卷积网络模型，以促进计算机视觉领域中对深度视觉表示的进一步研究。

## 1 INTRODUCTION

卷积网络 (ConvNets) 最近在大规模图像和视频识别中获得了巨大的成功 (例如 Krizhevsky et al., 2012; Zeiler & Fergus, 2013; Sermanet et al., 2014; Simonyan & Zisserman, 2014 )，这主要得益于大型公共图像仓库 (如 ImageNet (Deng et al., 2009)) 和高性能计算系统 (如 GPU 或大型分布式集群 (Dean et al., 2012)) 的支持。特别是，ImageNet Large-Scale Visual Recognition Challenge（ILSVRC）在深度视觉识别架构的发展中起到了重要作用，它成为了几代大规模图像分类系统的测试平台，从高维浅层特征编码（ILSVRC-2011的获胜者）到深度卷积网络（ILSVRC-2012的获胜者）。

随着卷积网络在计算机视觉领域变得越来越普及，有许多尝试去改进 Krizhevsky 等(2012) 的原始架构 (AlexNet) 以获得更高的准确率。例如，ILSVRC2013 中表现最好的提交 (Zeiler & Fergus, 2013; Sermanet et al., 2014) 使用了更小的感受野窗口和更小的第一卷积层步长。改进网络的另一方面是对整个图像和多个尺度进行密集的训练和测试 (Sermanet et al., 2014; Howard, 2014)。在本文中，我们关注的是卷积网络架构设计的另一个重要方面——它的深度。为此，我们固定了架构的其他参数，通过添加更多的卷积层稳步增加网络的深度，这要归功于在所有层中使用非常小 $(3×3)$ 的卷积滤波器，使其成为可能。

因此，我们设计出了明显更准确的卷积网络架构，它们不仅在 ILSVRC 分类和定位任务上取得了目前最佳的准确性，而且也适用于其他图像识别数据集，甚至在作为相对简单的管道 (例如，通过线性 SVM 分类深度特征而不微调) 的一部分时，也能达到令人满意的性能。我们已经发布了我们的两个性能最佳模型，以促进进一步的研究。

文章的其余部分组织如下。在第 2 节中，我们描述了我们的卷积网络配置。然后在第 3 节中介绍了图像分类训练和评估的详细信息，并在第 4 节中在 ILSVRC 分类任务上比较了这些配置。第 5 节总结了本文。为了完整起见，我们还在附录 A 中描述和评估了我们的 ILSVRC-2014 对象定位系统，并在附录 B 中讨论了非常深层特征对其他数据集的泛化能力。最后，附录 C 包含了主要论文修订的列表。

## 2 CONVNET CONFIGURATIONS


为了在公平的设置下测量增加的卷积网络深度带来的改进，我们的所有卷积网络层配置都遵循相同的设计原则，这些原则受 Ciresan et al. (2011); Krizhevsky et al. (2012) 的启发。在这一节中，我们首先描述了我们的卷积网络配置的通用布局 (2.1节)，然后详细描述了评估中使用的特定配置 (2.2 节)。我们的设计选择在 2.3 节中进行了讨论和与现有技术的比较。

### 2.1 ARCHITECTURE

在训练期间，我们卷积网络的输入是一个固定大小的 $224 \times 224$ RGB 图像。我们所做的唯一预处理是从每个像素中减去训练集上计算得出的平均 RGB 值。图像通过一组卷积层的堆叠，其中我们使用滤波器具有非常小的感受野：$3 \times 3$ (这是捕捉左/右，上/下，中心概念的最小大小)。在其中一个配置中，我们还使用了 $1×1$ 卷积滤波器，可以看作是输入通道的一个线性变换 (后面跟着非线性)。卷积步长固定为 1 像素；卷积层输入的空间填充使得卷积后空间分辨率得以保持，即对于 $3 \times 3$ 卷积层，填充为 1 像素。空间池化是通过5个最大池化层完成的，它们跟在一些卷积层后 (并非所有的卷积层后面都有最大池化)。最大池化在 $2 \times 2$ 像素窗口上执行，步长为 2。

一组卷积层的堆叠 (在不同架构中深度不同) 后面跟着 3 个全连接 (FC) 层：前 2 个都有 4096 个通道，第 3 个执行 1000 类的 ILSVRC 分类，因此包含 1000 个通道(每个类一个)。最后一层是 softmax 层。完全连接层的配置在所有网络中都是相同的。

所有隐藏层都配备了整流 (ReLU) 非线性。我们注意到，除了一个之外，我们的网络都不包含局部响应标准化 (LRN) 归一化：如第 4 节所示，这种归一化在 ILSVRC 数据集上并没有提升性能，但会增加内存消耗和计算时间。如果适用，LRN 层的参数是(AlexNet) 中的参数。

### 2.2 CONFIGURATIONS

本文评估的卷积网络配置如表 1 所示，每列一个。下面我们将按其名称 (A-E) 引用网络。所有配置都遵循第 2.1 节中介绍的通用设计，只在深度上有所不同：从网络 A 中的 11 个权重层 (8 个卷积层和 3 个全连接层) 到网络 E 中的 19 个权重层 (16 个卷积层和 3 个全连接层)。卷积层的宽度 (通道数) 相当小，从第一层的 64 开始，然后在每次最大池化层之后以 2 的因子增加，直到达到 512。

表 2 报告了每个配置的参数数量。尽管深度很大，但我们网络中的权重数量不大于宽度更大的卷积层和感受野的更浅层网络中的权重数量 (Sermanet等人,2014) 中的144M 个权重)。

### 2.3 DISCUSSION

我们的卷积网络配置与ILSVRC-2012比赛中表现最好的条目(Krizhevsky等,2012年)和ILSVRC-2013比赛(Zeiler和Fergus,2013年;Sermanet等,2014年)使用的配置非常不同。 我们没有在第一层卷积层中使用相对较大的感受野(例如,在(Krizhevsky等,2012年)中是11×11且步幅为4,在(Zeiler和Fergus,2013年; Sermanet等,2014年)中是7×7且步幅为2),而是在整个网络中使用非常小的3×3感受野,在每个像素处与输入卷积(步幅为1)。很容易看出,两个3×3卷积层的堆栈(中间没有空间池化)有一个5×5的有效感受野;三个这样的层有一个7×7的有效感受野。那么,例如,使用三个3×3卷积层的堆栈而不是单个7×7层有什么好处?首先,我们结合了三个非线性整流层,而不是单个,这使决策函数更加区分。其次,我们减少了参数的数量:假设三层3×3卷积堆栈的输入和输出都有C个通道,则该堆栈由3∗3∗2C^2=27C^2个权重参数化;同时,单个7×7卷积层需要7^2*C^2=49C^2个参数,即比例多了81%。这可以看作是对7×7卷积滤波器的一种正则化,迫使它们通过3×3滤波器分解(并在中间注入非线性)。合并1×1卷积层(配置C,表1)是一种增加决策函数非线性的方法,而不影响卷积层的感受野。尽管在我们的案例中,1×1卷积实质上是对相同维度空间(输入和输出通道数相同)的线性映射,但通过整流函数引入了额外的非线性。值得注意的是,1×1卷积层最近被Lin等人(2014年)在“网络中网络”体系结构中使用过。 小尺寸卷积滤波器以前由Ciresan等人使用(2011年),但是他们的网络明显比我们的浅,他们也没有在大规模的ILSVRC数据集上评估。 Goodfellow等人(2014年)将深度卷积网络(11个权重层)应用于街道数字识别任务,并表明增加的深度导致了更好的性能。 GoogLeNet(Szegedy等,2014年)是ILSVRC-2014分类任务的一个表现最佳的条目,它与我们的工作独立开发,但类似之处在于它基于非常深的卷积网络(22个权重层)和小的卷积滤波器(除了3×3,他们还使用1×1和5×5卷积)。然而,他们的网络拓扑比我们的复杂得多,第一层的特征图空间分辨率更积极地减小以减少计算量。正如第4.5节所示,就单网络分类准确率而言,我们的模型胜过Szegedy等人(2014年)的模型。

## Reference

[1]: https://blog.csdn.net/C_chuxin/article/details/82833070	"【论文翻译】VGG网络论文中英对照翻译"

