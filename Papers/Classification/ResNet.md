# Deep Residual Learning for Image Recognition

## Abstract

更深的神经网络更难训练。我们提出一个残差学习框架，使得训练比以前的网络深得多的网络容易。我们明确地将层重新定义为学习关于输入的残差，而不是学习无参照的函数。我们提供了全面的实验性证据表明这些残差网络更加容易优化，并且可以从大幅增加的深度中提升精度。在 ImageNet 数据集上，我们评估深度高达 152 层的残差网络——比 VGG 网络深 8 倍，但仍然具有更低的复杂性。一个残差网络的集成在 ImageNet 测试集上取得了 3.57% 的错误率。这个结果在 ILSVRC 2015 分类任务中获得了第一名。我们还用 100 层和 1000 层在 CIFAR-10 上进行了分析。

表征的深度对许多视觉识别任务至关重要。仅仅由于我们的极其深的表征，我们在 COCO 目标检测数据集上获得了 28% 的相对提升。深度残差网络是我们在 ILSVRC & COCO 2015 竞赛中的提交的基线，在那我们还赢得了 ImageNet 检测、ImageNet 定位、COCO 检测和 COCO 分割的第一名。

## 1. Introduction

深度卷积神经网络为图像分类带来了一系列的突破。深度网络以端到端的多层方式自然地集成了低/中/高级特征和分类器，而特征的 "级别" 可以通过堆叠层的数量 (深度) 来丰富。最近的证据表明网络的深度是至关重要的，而在具有挑战性的 ImageNet 数据集位于前列的结果都利用了 "非常深" 的模型，深度从 16 到 30。许多其他重要的视觉识别任务也从非常深的模型中获益良多。

受深度的重要性的驱使，一个问题出现了：学习更好的网络就像堆叠更多的层一样容易吗？回答这个问题的一个障碍是臭名昭著的梯度消失/爆炸问题，它从一开始就阻碍了收敛。然而，这个问题很大程度上通过归一化后的初始化和中间的归一化层得到了解决，它使得具有数十层的网络开始收敛于使用反向传播的随机梯度下降 (SGD)。

当更深的网络开始收敛时，一个退化问题就暴露出来了：随着网络的深度的增加，准确性达到饱和 (可能并不奇怪)  然后迅速退化。令人意外的是，这种退化并不是过拟合造成的，在适当深度的模型上添加更多的层会导致更高的训练误差，如 [11, 42] 中所报道的，并通过我们的实验得到验证。图 1 展示了一个典型的例子。

<img src="assets/ResNet_fig1.png" title="图1">

图 1：使用 20 层和 50 层 "普通" 网络在 CIFAR-10 上的训练错误率 (左) 和 测试错误率 (右)。更深的网络有更高的训练错误率和测试错误率。ImageNet 上同样的现象在图 4 中展示。

(训练精度的) 退化表明并非所有的系统都同样容易优化。让我们考虑一个较浅的架构以及在它基础上添加更多层的较深的对应架构。通过构造更深的模型，存在一种解决方案：添加的层是恒等映射，而其他的层是从学习后的较浅的模型拷贝而来。这种构造方法的存在表明，深度模型应该不会产生比浅层模型更高的训练误差。但实验表明，我们现有的优化器无法找到比这种构建方案更好的解决方案 (或无法在可行时间内做到)。

在本论文中，我们通过引入一种深度残差学习框架来解决退化问题。与其希望每几个堆叠的层直接拟合一个期望的底层映射，不如显示地让这些层拟合一个残差映射。形式上，将期望的底层映射表示为 $\mathcal{H}(\bold{x})$，我们让堆叠的非线性层拟合另外一个映射 $\mathcal{F}(\bold{x}) := \mathcal{H}(\bold{x}) - \bold{x}$。原来的映射被改写成 $\mathcal{F}(\bold{x}) + \bold{x}$。我们假设优化残差映射比优化原始的更容易。最极端的情况是，如果一个恒等映射是最优的，那么将残差推向 0 比通过一堆非线性层来拟合恒等映射更容易。

表达式 $\mathcal{F}(\bold{x}) + \bold{x}$ 可以使用 "跳跃连接" ("shortcut connections") (图 2) 的前馈神经网络来实现。跳跃连接是指跳过一层或多层的连接。In our case，跳跃连接简单地执行恒等映射，它们的输出被添加到堆叠的层的输出上 (图 2)。恒等跳跃连接既不增加参数，也不增加计算复杂性。整个网络仍然可以通过 SGD 使用反向传播进行端到端的训练，并且可以很容易地使用常用的库 (如 Caffe) 实现，无需修改优化器。

<img src="assets/ResNet_fig2.png" title="图2">

图 2：Residual learning：a building block

我们在 ImageNet 上进行了全面的实验，以展示退化问题并评估我们的方法。我们的研究表明：1) 我们的非常深的残差网络容易优化，但对应的 "普通" 网络 (简单地堆叠层) 在深度增加时表现出更高的训练误差；2) 我们的深度残差网络可以很容易地从大幅度增加的深度中获得精度提升，产生比之前的网络好很多的结果。

在 CIFAR-10 数据集上也显示了类似的现象，这表明我们的方法的优化的困难和效果并不仅仅是与特定的数据集有关系。我们在这个数据集上成功训练了 100 层的模型，并探索了 1000 层以上的模型。

在 ImageNet 分类数据集上，我们通过非常深的残差网络获得了极好的结果。我们的 152 层的残差网络是 ImageNet 上出现过的最深的网络，但复杂度比 VGG 网络更低。我们的集成 (ensemble) 在 ImageNet 测试集上获得了 3.57% 的 top-5 错误率，并赢得了 ILSVRC 2015 分类竞赛的第一名。非常深的表征在其他识别任务上也有极好的泛化性能，并让我们在 ILSVRC & COCO 2015 竞赛中的 ImageNet 检测、ImageNet 定位、COCO 检测和 COCO 分割取得了第一名。这一强有力的证据表明，残差学习的原则是通用的，我们希望它能适用于其他视觉和非视觉的问题。