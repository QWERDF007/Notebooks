# Deep Residual Learning for Image Recognition

## Abstract

更深的神经网络更难训练。我们提出一个残差学习框架，使得训练比以前的网络深得多的网络容易。我们明确地将层重新定义为学习关于输入的残差，而不是学习无参照的函数。我们提供了全面的实验性证据表明这些残差网络更加容易优化，并且可以从大幅增加的深度中提升精度。在 ImageNet 数据集上，我们评估深度高达 152 层的残差网络——比 VGG 网络深 8 倍，但仍然具有更低的复杂性。一个残差网络的集成 (ensemble) 在 ImageNet 测试集上取得了 3.57% 的错误率。这个结果在 ILSVRC 2015 分类任务中获得了第一名。我们还用 100 层和 1000 层在 CIFAR-10 上进行了分析。

表征的深度对许多视觉识别任务至关重要。仅仅由于我们的极其深的表征，我们在 COCO 目标检测数据集上获得了 28% 的相对提升。深度残差网络是我们在 ILSVRC & COCO 2015 竞赛中的提交的基线，在那我们还赢得了 ImageNet 检测、ImageNet 定位、COCO 检测和 COCO 分割的第一名。

## 1. Introduction

深度卷积神经网络为图像分类带来了一系列的突破。深度网络以端到端的多层方式自然地集成了低/中/高级特征和分类器，而特征的 "级别" 可以通过堆叠层的数量 (深度) 来丰富。最近的证据表明网络的深度是至关重要的，而在具有挑战性的 ImageNet 数据集位于前列的结果都利用了 "非常深" 的模型，深度从 16 到 30。许多其他重要的视觉识别任务也从非常深的模型中获益良多。

受深度的重要性的驱使，一个问题出现了：学习更好的网络就像堆叠更多的层一样容易吗？回答这个问题的一个障碍是臭名昭著的梯度消失/爆炸问题，它从一开始就阻碍了收敛。然而，这个问题很大程度上通过规范化后的初始化和中间的规范化层得到了解决，它使得具有数十层的网络开始收敛于使用反向传播的随机梯度下降 (SGD)。

当更深的网络开始收敛时，一个==退化问题==就暴露出来了：随着网络的深度的增加，准确性达到饱和 (可能并不奇怪)  然后迅速退化。令人意外的是，==这种退化并不是过拟合造成的==，在适当深度的模型上添加更多的层会导致更高的训练误差，如 [11, 42] 中所报道的，并通过我们的实验得到验证。图 1 展示了一个典型的例子。

<img src="assets/ResNet_fig1.png" title="图1">

**图 1：** 使用 20 层和 50 层 "普通" 网络在 CIFAR-10 上的训练错误率 (左) 和 测试错误率 (右)。更深的网络有更高的训练错误率和测试错误率。ImageNet 上同样的现象在图 4 中展示。

(训练精度的) 退化表明并非所有的系统都同样容易优化。让我们考虑一个较浅的架构以及在它基础上添加更多层的较深的对应架构。通过构造更深的模型，存在一种解决方案：添加的层是恒等映射，而其他的层是从学习后的较浅的模型拷贝而来。这种构造方法的存在表明，深度模型应该不会产生比浅层模型更高的训练误差。但实验表明，我们现有的 solvers 无法找到比这种构建方案更好的解决方案 (或无法在可行时间内做到)。

**ps：** 这里的 solvers 指的是 SGD 等优化器，在实验部分有说到 SGD solver。

在本论文中，我们通过引入一种==深度残差学习框架==来解决退化问题。与其希望每几个堆叠的层直接拟合一个期望的底层映射，不如显示地让这些层拟合一个残差映射。形式上，将期望的底层映射表示为 $\mathcal{H}(\mathbf{x})$ ，我们让堆叠的非线性层拟合另外一个映射 $\mathcal{F}(\mathbf{x}) := \mathcal{H}(\mathbf{x}) - \mathbf{x}$ 。原来的映射被改写成 $\mathcal{F}(\mathbf{x}) + \mathbf{x}$ 。我们假设优化残差映射比优化原始的更容易。最极端的情况是，如果一个恒等映射是最优的，那么将残差推向 0 比通过一堆非线性层来拟合恒等映射更容易。

表达式 $\mathcal{F}(\mathbf{x}) + \mathbf{x}$ 可以使用 "shortcut connections" (图 2) 的前馈神经网络来实现。Shortcut connections 是指跳过一层或多层的连接。在我们的方法中，shortcut connections 简单地执行恒等映射，它们的输出被添加到堆叠的层的输出上 (图 2)。恒等 shortcut connections 既不增加参数，也不增加计算复杂性。整个网络仍然可以通过 SGD 使用反向传播进行端到端的训练，并且可以很容易地使用常用的库 (如 Caffe) 实现，无需修改 solvers。

<img src="assets/ResNet_fig2.png" title="图2">

**图 2：** 残差学习：一个构建块

我们在 ImageNet 上进行了全面的实验，以展示退化问题并评估我们的方法。我们的研究表明：1) 我们的非常深的残差网络容易优化，但对应的 "普通" 网络 (简单地堆叠层) 在深度增加时表现出更高的训练误差；2) 我们的深度残差网络可以很容易地从大幅度增加的深度中获得精度提升，产生比之前的网络好很多的结果。

在 CIFAR-10 数据集上也显示了类似的现象，这表明我们的方法的优化的困难和效果并不仅仅是与特定的数据集有关系。我们在这个数据集上成功训练了 100 层的模型，并探索了 1000 层以上的模型。

在 ImageNet 分类数据集上，我们通过非常深的残差网络获得了极好的结果。我们的 152 层的残差网络是 ImageNet 上出现过的最深的网络，但复杂度比 VGG 网络更低。我们的集成 (ensemble) 在 ImageNet 测试集上获得了 3.57% 的 top-5 错误率，并赢得了 ILSVRC 2015 分类竞赛的第一名。非常深的表征在其他识别任务上也有极好的泛化性能，并让我们在 ILSVRC & COCO 2015 竞赛中的 ImageNet 检测、ImageNet 定位、COCO 检测和 COCO 分割取得了第一名。这一强有力的证据表明，残差学习的原则是通用的，我们希望它能适用于其他视觉和非视觉的问题。

## 2. Related Work

**Residual Representations.** 在图像识别中，[VLAD](https://hal.inria.fr/inria-00633013/document) 是一个与字典相关的残差向量进行编码的表示，而 [Fisher Vector](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.71.7388&rep=rep1&type=pdf) 可以表示为 VLAD 的概率版本。两者都是图像检索和分类的强有力的浅层表示。对于矢量量化，编码残差向量被证明比编码原始向量更加有效。

在低级的视觉和计算机图形学中，为了求解偏微分方程 (PDEs)，广泛使用的多重网格法将系统重新表示为多尺度的子问题，其中每个子问题负责粗尺度和细尺度之间的残差解。多重网格的另外一种选择是 hierarchical basis preconditioning，它依赖于表示两个尺度之间的残差向量的变量。已有研究表明，这些 solvers 比那些不知道残差本质的标准 solvers 收敛快得多。这些方法表明，好的 reformulation 和 preconditioning 能简化优化。

**Shortcut Connections.** Shortcut connections 的实践和理论已经被研究了很长时间。一个训练多层感知机 (MLPs) 的早期实践是添加一个线性层连接网络的输入到输出。在 [44, 24]，一些中间层直接连接到辅助分类器，用于处理梯度消失/爆炸。论文 [39, 38, 31, 47] 提出通过 shortcut connections 实现集中层响应、梯度和传播误差。在 [44]，一个 "inception" 层由一个 shortcut 分支和几个更深的分支组成。

与我们的工作的同一时期，"highway networks" 提出了有门函数的 shortcut connections。这些门是依赖于数据并且有参数，相反，我们的恒等 shortcuts 则没有参数。当门控 shortcut "关闭" (接近 0)，highway networks 中的层代表非残差函数。相反，我们的 formulation 则总是学习残差函数；我们的恒等 shortcuts 永远不会关闭，所有的信息总是被通过，还有一些额外的要学习的残差函数。另外，highway networks 没有展示随着深度的极大提升 (例如超过 100 层) 获得精度的提升。

## 3. Deep Residual Learning

### 3.1. Residual Learning

让我们把 $\mathcal{H}(\mathbf{x})$ 看作是由几个堆叠的层 (不一定是整个网络) 拟合的底层映射， $\mathbf{x}$ 表示这些层的第一层的输入。如果==假设多个非线性层能渐进地逼近复杂的函数==，那么就等价于假设它们可以渐进地逼近残差函数，即 $\mathcal{H}(\mathbf{x}) - \mathbf{x}$ (假设输入和输出是相同维度的)。因此，与其期望堆叠的层逼近 $\mathcal{H}(\mathbf{x})$ ，不如显示地让这些层逼近一个残差函数 $\mathcal{F}(\mathbf{x}) := \mathcal{H}(\mathbf{x}) - \mathbf{x}$ 。因此，原始函数就变成了 $\mathcal{F}(\mathbf{x}) + \mathbf{x}$ 。虽然这两种形式都应该能够渐进地逼近期望函数 (如假设的那样)，但学习的难易程度可能不同。

这个 reformulation 是由关于退化问题的反直觉现象 (图 1 左) 所激励的。正如我们在引言中所讨论的，如果添加的层可以被构建为恒等映射，一个更深的模型的训练误差应该不大于它的对应的浅层模型。退化问题表明 solvers 在用多个非线性层逼近恒等映射时可能有困难。使用残差学习 reformulation，如果恒等映射是最优的，solvers 可以简单地将多个非线性层的权重趋于零来逼近恒等映射。

在实际情况中，恒等映射不太可能是最优的，但我们的 reformulation 可能有助于 precondition 问题。如果最优的函数是接近于恒等映射而不是零映射，那么对于 solvers 来说，找到一个关于恒等映射的扰动比学习一个新函数更容易。我们通过实验 (图 7) 表明学习到的残差函数整体上响应较小，这表明恒等映射提供了合理的 preconditioning。

### 3.2. Identity Mapping by Shortcuts

我们每隔几层采用残差学习。一个构造块如图 2 所示。形式上，在本论文中我们考虑将一个构造块定义为：

$$
\mathbf{y} = \mathcal{F}(\mathbf{x}, \{W_i\}) + \mathbf{x} \tag{1}
$$

这里的 $\mathbf{x}$ 和 $\mathbf{y}$ 是被考虑的层的输入和输出向量。函数 $\mathcal{F}(\mathbf{x}, W_i)$ 表示要学习的残差映射。对于图 2 中的两层的示例， $\mathcal{F} = W_2\sigma(W_1\mathbf{x})$ ，其中 $\sigma$ 表示 ReLU，并且为了简化表示，偏置被省略了。运算 $\mathcal{F} + \mathbf{x}$ 是通过 shortcut connection 和元素级别的加法完成的。我们在加法后使用了第二次非线性 (例如， $\sigma(\mathbf{y})$ ，见图 2)。

等式 (1) 中的 shortcut connections 既不引入额外的参数，也不引入计算复杂度。这不仅在实践中很有吸引力，而且在我们比较普通网络和残差网络时也很重要。我们可以公平地比较同时具有相同数量的参数、深度、宽度和计算成本 (除了可忽略的元素级加法) 的普通网络和残差网络。

等式 (1) 中的 $\mathbf{x}$ 和 $\mathcal{F}$ 的维度必须相等。如果不相等 (例如，改变输入/输出通道)，我们可以对 shortcut connections 进行一个线性投影 $W_s$ 来匹配维度：

$$
\mathbf{y} = \mathcal{F}(\mathbf{x}, \{W_i\}) + W_s \mathbf{x} \tag{2}
$$

我们也可以在等式 (1) 中使用方阵 $W_s$ 。但我们将通过实验证明，恒等映射对于解决退化问题是足够的，并且是经济的，因此 $W_s$ 只在匹配维度时使用。

残差函数 $\mathcal{F}$ 的形式是灵活的。在本论文中的实验涉及到的一个函数 $\mathcal{F}$ ，它有两层或三层，也可以有更多层。但如果 $\mathcal{F}$ 只有一层，等式 (1) 类似于线性层：$\mathbf{y} = W_1 \mathbf{x} + \mathbf{x}$ ，我们没有观察到它的优点。

我们还注意到，尽管为了简单起见，上述符号是关于全连接层的，但它们适用于卷积层。函数 $\mathcal{F}(\mathbf{x}, \{W_i\})$ 可以表示多个卷积层。元素级加法在两个特征映射上，逐个通道执行。

### 3.3. Network Architectures

我们测试了各种普通/残差网络，并观察到一致的现象。为了提供实例供讨论，我们在下面描述了两个 ImageNet的模型。

**普通网络。** 我们的普通基线 (图 3 中间) 主要受到 VGG 网络 (图 3 左) 的思想启发。卷积层大部分有 $3 \times 3$ 的滤波器，并遵循两个设计原则：(i) 对于相同输出 feature map 大小，层有相同数量的滤波器；(ii) 如果 feature map 的大小减半，滤波器数量增加一倍，以维持每层的时间复杂度。我们直接通过步幅为 2 的卷积层进行下采样。网络以一个全局平均汇聚层和一个 1000 路带有 softmax 的全连接层结束。图 3 (中间) 中有权重的层的总数是 34。

值得注意的是，与 VGG 网络 (图 3 左) 相比，我们的模型滤波器更少，复杂性更低。我们的 34 层基线模型有 36 亿 FLOPs (乘-加)

**ps：** FLOPs——浮点运算次数 (Floating Point Operations)；FLOPS——每秒浮点运算次数 (Floating Point Operations Per Second)

**残差网络。** 在上述的普通网络的基础上，我们插入 shortcut connections (图 3 右)，将网络转化为对应的残差版本。当输入和输出是相同的维度时，恒等 shortcut (等式 (1)) 可以直接使用 (图 3 中的实线 shortcuts)。当维度增加时 (图 3 中的虚线 shortcuts)，我们考虑两种选择：(A) shortcut 通过额外的零填充来增加维度，仍然进行恒等映射；(B) 等式(2) 中的投影被用于匹配维度 (通过 ==$1 \times 1$ 的卷积==完成)。对于这两个选项，当 shortcuts 跨越两种尺寸的 feature maps 时，它们的步幅都为 2。

<img src="assets/ResNet_fig3.png" title="图3">

**图 3：** ImageNet 上的网络架构示例。**左：** VGG-19 模型 (196 亿 FLOPs) 作为参考。**中间：** 一个有 34 层参数的普通网络 (36 亿 FLOPs)。**右：** 一个有 34 层参数的残差网络 (36 亿 FLOPs)。虚线连接的 shortcuts 提升维度。表 1 展示了更多细节和其他的变种。

### 3.4. Implementation

我们在 ImageNet 的实现遵循 [21, 41] 中的实验。图像被缩放到短边为 [256, 480] 中的随机采样，用于缩放增强。从图像或者它的水平翻转中随机裁剪一个 $224 \times 224$ ，并减去每个像素的平均值 (训练集的RGB平均值)。使用 [21] 中标准的颜色增强。我们按照 [16] 在每个卷积之后，激活之前采样批标准化 (BN)。我们按照 [13] 初始化权重，并从头开始训练普通/残差网络。我们使用批量大小为 256 的 SGD。学习率从 0 开始，当误差稳定时将学习率除以 10，模型训练 $60 \times 10^4$ 次迭代 (一个 batch 算一次 iteration)。我们使用权重衰减为 0.0001，动量为 0.9。我们没有使用 dropout，遵循 [16] 中的实验。

测试时，为了比较研究，我们采用标准的 10-crop 测试 (四个角落块和中心块以及对应的翻转)。为了最佳结果，我们采用了 [41, 13] 中的全卷积形式，并对多个尺度上 (图像被调整大小到短边为 {224, 256, 384, 480, 640}) 的分数取平均。

## 4. Experiments

### 4.1. ImageNet Classification

我们在 1000 类的 ImageNet 2012 分类数据集上评估我们的方法。在 120 万训练图像上对模型进行训练，在 50 k 验证图像上对模型进行评估。我们还获得了 100k 测试图像的最终结果，由测试服务报告。

**普通网络。** 我们首先评估了 18 层和 34 层的普通网络。34 层的普通网络如图 3 (中间) 所示 。18 层的网络也是类似的形式。详细架构见表 1.

<img src="assets/ResNet_table1.png" title="表1">

**表 1：** ImageNet 上的架构。构造块展示在括号中 (也可参见图 5)，伴有堆叠的块的数量。下采样由 conv3_1，conv4_1 和 conv5_1 执行，步长为 2。

<img src="assets/ResNet_fig4.png" title="图4">

**图 4：** ImageNet 上的训练。细线表示训练误差，粗线表示中心裁剪的验证误差。左：18 层和 34 层的普通网络。右：18 层和 34 层的残差网络。在这张图中，与普通网络相比，残差网络没有额外的参数。

<img src="assets/ResNet_table2.png" title="图4">

**表 2：** ImageNet 验证的 top-1错误率 (%，10-crop 测试)。这里的 ResNet 与普通网络相比没有额外的参数。图 4 展示了训练过程。

表 2 的结果表明，较深的 34 层普通网络比较浅的 18 层具有更高的验证误差。为了揭示原因，在图 4 (左) 中，我们比较了它们的训练过程中的训练/验证错误。我们观察到退化问题——34 层的普通网络在整个训练过程中具有更高的训练误差，尽管 18 层的普通网络的解空间是 34 层网络的解空间的子空间。

我们认为这种优化困难不太可能是由梯度消失引起的。这些普通网络使用 BN 训练，确保正向传播具有非零方差。我们也验证了使用 BN 反向传播梯度呈现出良好的 norms。因此正向和方向信号都没有消失。事实上，34 层的普通网络仍能取得有竞争性的精度，说明 solver 一定程度上是可行的。我们猜想深的普通网络可能有指数级的低的收敛速率，这影响了训练误差的降低。出现这种优化困难的原因将在未来进行研究。

**残差网络。** 接下来我们评估 18 层和 34 层的残差网络 (ResNets)。基线架构和上述的普通网络相同，只是给每对 $3 \times 3$ 的滤波器添加一个 shortcut connection，如图 3。在第一个比较中 (表 2 和图 4 右)，我们使用给所有 shortcuts 使用恒等映射，并使用零填充来提升维度 (选项 A)。因此与普通的网络相比，没有额外的参数。

我们从表 2 和图 4 中得到三个主要的观察结果。第一，这种情况与残差网络相反—— 34 层 ResNet 比 18 层 ResNet 更好 (2.8%)。更重要的是，34 层的 ResNet 展现出相当低的训练误差，并且能够泛化到验证数据。这表明在这种情况下，退化问题得到了很好的解决，并且我们设法通过提升深度来获得精度。

第二，与普通的网络相比，34 层的 ResNet 的 top-1 误差减少了 3.5% (表 2)，这是因为成功地减少了训练误差 (图 4 右 vs. 左)。这一比较验证了残差学习在极深系统上的有效性。

最后，我们还注意到，18 层的普通/残差网络精度相同 (表 2)，但 18 层的残差网络收敛更快 (图 4 右 vs. 左)。当网络是 "不过度深的网络" 时 (此处是 18 层)，目前的 SGD solver 仍然能够为普通网络找到好的解。在这种情况下，ResNet 通过在早期提供更快的收敛使优化变容易。

<img src="assets/ResNet_table3.png" title="表3">

**表 3：** ImageNet 验证集上的错误率 (%，10-crop 测试)。VGG-16 是基于我们的测试。ResNet-50/101/152 使用的是选项 B，仅使用投影来提升维度。

<img src="assets/ResNet_table4.png" title="表4">

**表 4：** ImageNet 验证集 (除了报告在测试集上的 $^†$) 上单模型的错误率 (%)。

<img src="assets/ResNet_table5.png" title="表5">

**表 5：** 模型集成的错误率 (%)。top-5 错误率是在 ImageNet 的测试集上的，由测试服务器报告。

**Identity vs. Projection Shortcuts.** 我们已经展示了无额外参数的恒等映射 shortcuts 有助于训练。接下来我们研究投影 shortcuts (等式 (2))。在表 3 中，我们比较了三个选项：(A) ==零填充 shortcuts== 被用来提升维度，并且所有的 shortcuts 都没有额外参数 (与表 2 和图 4 右相同)；(B) ==投影 shortcuts== 被用来提升维度，而其他 shortcuts 是恒等的；(C) 所有 shortcuts 都是投影。

表 3 展示了这三个选项都比普通网络更好。B 比 A 稍微好点。我们认为这是因为 A 中的零填充的维度没有残差学习。C 稍微比 B 好，我们认为这归功于由许多 (13) 投影 shortcuts 所引入的额外参数。但 A/B/C 中的微小差异表明投影 shortcuts 对于解决退化问题并不是必不可少的。所以在本文剩下部分，我们没有使用选项 C，以降低内存/时间复杂度和模型大小。恒等 shortcuts 对于不增加下面介绍的 bottleneck 架构的复杂性尤为重要。

<img src="assets/ResNet_fig5.png" title="图5">

**图 5：** 一个关于 ImageNet 更深的残差函数 $\mathcal{F}$ 。左：图 3 中的一个构建块 (在 $56 \times 56$ 的 feature maps 上)。

**Deeper Bottleneck Architectures.** 接下来我们描述我们在 ImageNet 上更深的网络。考虑到我们所能承受的训练时间，我们修改构建块为一个 bottleneck 设计。对于每个残差函数 $\mathcal{F}$ ，我们使用 3 层的堆叠代替 2 层的 (图 5)。这三层分别是 $1 \times 1$ ， $3 \times 3$ 和 $1 \times 1$ 的卷积，其中 $1 \times 1$ 的层负责减少和增加 (恢复) 维度，使 $3 \times 3$ 的层成为一个有更小输入/输出维度的 bottleneck。

没有额外参数的恒等 shortcuts 对于 bottleneck 架构尤为重要。如果图 5 中的恒等 shortcut 替换为投影的，可以证明，由于 shortcut 连接到两个高维的端点，时间复杂性和模型大小会翻倍。因此恒等 shortcut 为 bottleneck 设计带来了更有效的模型。

**50 层的 ResNet：** 我们将 34 层网络中的每个 2 层的块替换为这个 3 层的 bottleneck 块，从而得到一个 50 层的 ResNet (表 1)。我们使用选项 B 来提升维度。这个模型有 38 亿 FLOPs。

**101 层和 152 层的 ResNets：** 我们使用了更多的 3 层的块构造了 101 层和 152 层的 ResNets。值得注意的是，虽然深度显著地提升，但是 152 层的 ResNet (113 亿 FLOPs) 仍然比 VGG-16/19 网络 (153/196 亿 FLOPs) 具有更低的复杂度。

50/101/152 层的 ResNets 比 34 层的更准确一些 (表 3 和 4)。我们没有观察到退化问题，并因此从大幅提升的深度中获得了显著的精度增益。深度的好处可以在所有的评估指标 (表 3 和 表 4) 中看到。

**与 State-of-the-art 方法比较。** 在表 4 中，我们与之前最好的单模型的结果进行了比较。我们的基线 34 层的 ResNet 取得了非常有竞争力的精度。我们的 152 层 ResNet 单模型 top-5 验证错误率为 4.49%。这个单模型结果优于所有之前的集成的结果 (表 5)。我们将六个不同深度的模型组合在一起形成一个集成 (在提交时只有两个 152 层模型)。这在测试集上得到了 3.57% 的错误率 (表 5)。这一条目赢得了 ILSVRC 2015 的第一名。

### 4.2. CIFAR-10 and Analysis

我们在 CIFAR-10 数据集上进行了更多的研究，该数据集由 10 个类别的 50k 训练图像和 10k 测试图像组成。我们在训练集上进行实验，并在测试集上评估。我们关注的是极深网络的表现，而不是推出一个 state-of-the-art 结果，因此我们有意地使用如下所示的简单架构。

普通/残差架构遵循图 3 (中/右) 的形式。网络的输入是 $32 \times 32$ 的图像，减去了每个像素的平均值。第一层是 $3 \times 3$ 的卷积。然后我们在大小为 {32, 16, 8} 的 feature maps 使用一个有 $3 \times 3$ 的卷积的 6n 层的堆叠，每个 feature map 尺寸使用 2n 层。滤波器的数量分别是 {16, 32, 64}。下采样由步长为 2 的卷积执行。网络以一个全局平均汇聚，一个 10 路全连接层和 softmax 结束。一共有 6n+2 堆叠的有权重的层。下表总结了架构：

<img src="assets/ResNet_tableA.png" title="表A">

当使用 shortcut connections 时，它们被连接到成对的 $3 \times 3$ 的层 (总共 3n shortcuts)。在这个数据集上，我们在所有的情况下 (例如选项 A) 都使用恒等 shortcuts，所以我们的残差模型和对应的普通模型具有相同的深度、宽度和参数数量。

<img src="assets/ResNet_table6.png" title="表6">

我们使用的权重衰减为 0.0001，动量为 0.9，并采用 [13] 中的权重初始化和 BN，但没有 dropout。这些模型以小批量大小为 128 在两个 GPUs 上训练。我们从 0.1 的学习率开始，并在 32k 和 48k 个 iterations 时将学习率除 10，并在 64k 个 iterations 时终止训练，这是在45k/5k 训练/验证分割中确定的。我们的训练遵循 [24] 中的简单数据增强：每条边填充 4 个像素，然后从填充后的图像或它的水平翻转中随机采样一个 $32 \times 32$ 的裁剪。对于测试，我们仅在原始的 $32 \times 32$ 图像上进行评估。

我们比较了 n = {3,5,7,9}，得到了 20，32，44 和 56 层的网络。图 6 (左) 展示了普通网络的表现，深度普通网络随着深度增加展现出更高的训练误差。这种现象和在 ImageNet 上的相似 (图 4 左)，在 MNIST 也一样 (见 [42])，表明这样的优化困难是一个 fundamental problem。

图 6 (中) 展示了 ResNets 的表现。和 ImageNet 的例子 (图 4 右) 相似，我们的 ResNets 设法克服优化困难，并展示出随着深度提升获得精度增益。

我们进一步探索了 n = 18，得到了一个 110 层的 ResNet。在这种情况下，我们发现 0.1 的初始学习率有点太大而无法开始收敛。因此我们用 0.01 来预热训练，直到训练误差低于 80% (大约 400 iterations)，然后回到 0.1 并继续训练。其余的学习计划和之前一样。这个 110 层的网络收敛得好 (图 6 中)。它比其他深并窄的网络如 FitNet [35] 和 Highway [42] (表 6) 具有更少的参数，然而是 state-of-the-art 的结果之一 (6.43%，表 6)。

<img src="assets/ResNet_fig6.png" title="图6">

**图 6：** CIFAR-10 上的训练。虚线表示训练误差，粗线表示测试误差。左：普通网络。110 层普通网络的训练误差高于 60% 而没有展示。中间：ResNets。右：110 层和 1202 层的 ResNets。

<img src="assets/ResNet_fig7.png" title="图7">

**图 7：** CIFAR-10 上的层响应的标准差 (std)。这些响应是 $3 \times 3$ 的层的输出，在 BN 之后和非线性之前。上：这些响应按它们原本的顺序展示。下：这些响应按降序排序。

**层的响应分析。** 图 7 展示了层响应的标准差 (std)。这些响应是每个 $3 \times 3$ 的层的输出，在 BN 之后和在非线性 (ReLU/加法) 之前。对于 ResNet，这个分析揭示了残差函数的响应强度。图 7 展示了 ResNets 的响应普遍比普通的网络小。这些结果支持了我们的基本动机 (3.1 节)。我们也注意到更深的 ResNet 有更小的响应幅度，图 7 中的 ResNet-20，56 和 110 的比较可以证明这一点。当层数越多，ResNets 的单个层倾向于对信号的修改越少。

**探索超过 1000 层。** 我们探索了一个超过 1000 层的极其深的模型。我们设 n = 200，得到了一个 1202 层的网络，按照上面描述的进行训练。我们的方法没有表示出优化困难，并且这个 1000 层的网络能够取得 < 0.1% 的训练误差 (图 6 右)。它的测试误差仍然相当不错 (7.93%，表 6)。

但在如此深的模型上仍然有一些为解决的问题。1202 层网络的测试结果比我们的 110 层网络的结果更差，虽然两者都有相似的训练误差。我们认为这是因为过拟合。1202 层的网络对于这个小数据集来说可能太大了 (19.4M)。在这个数据集上采取诸如 maxout [10] 或者 dropout 等强正则来获得最佳的结果。在本论文中，我们没有使用 maxout/droput，在不分散对优化困难的关注下，只是简单地通过设计深的和窄的架构来进行正则化。但组合更强的正则化可能会改善结果，我们将在未来研究它。

### 4.3. Object Detection on PASCAL and MS COCO

<img src="assets/ResNet_table7.png" title="表7">

**表 7：** 在 PASCAL VOC 2007/2012 测试集上使用基线 Faster R-CNN 的目标检查 mAP (%)。更好的结果见表 10 和表 11。

<img src="assets/ResNet_table8.png" title="表8">

**表 8：** 在 COCO 验证集上使用基线 Faster R-CNN 的目标检查结果 mAP (%)。更好的结果见表 9。

我们的方法在其他的识别任务上有良好的泛化性能。表 7 和表 8 展示了 PASCAL VOC 2007 和 2012 和 COCO 的基线结果。我们采用 Faster R-CNN [32] 作为检测方法。这里我们感兴趣的是用 ResNet-101 替换 VGG 的改进。这两种模型的检测的实现 (见附录) 是相同的，所以增益只能归功于更好的网络。最引人注目的是，在具有挑战性的 COCO 数据集上，我们在 COCO 标准指标 (mAP@[.5, .95]) 获得了一个 6.0% 的提升，这相对提升了 28%。这种增益完全是由于学到的表征。

基于深度残差网络，我们赢得了 ILSVRC & COCO 2015 比赛多个赛道的第一名：ImageNet 检测、ImageNet 定位、COCO 检测和 COCO 分割。详情见附录。

