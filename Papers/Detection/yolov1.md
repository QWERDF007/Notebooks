# [You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/pdf/1506.02640.pdf)

## Abstract

我们提出了 YOLO，一种新的目标检测方法。先前的目标检测工作重新应用 (repurposes) 分类器来进行检测。相反，我们将目标检测定义为一个关于空间上分离的边界框和相关类别的概率的回归问题。在一次评估中，单个神经网络直接从完整的图像预测边界框和类别概率。由于整个检测流水线 (pipeline) 是一个单一神经网络，因此可以在检测性能上直接进行端到端优化。

我们的统一架构非常快。我们的基础 YOLO 模型以 45 帧/秒的速度实时处理图像。该网络的一个更小的版本，Fast YOLO，能达到惊人的 155 帧/秒，同时仍然取得了其他实时检测器的两倍的 mAP。与其他最先进的检测系统相比，YOLO 产生更多的定位错误，但更少可能在背景区域上产生误报 (假阳)。最后，YOLO 学习目标的一般表示。当从自然图像推广到其他领域 (如艺术品) 时，它优于其他检测方法，包括 DPM 和 R-CNN。

## 1. Introduction

人们扫一眼图像就能立刻知道图像中有什么物体，它们在哪里，已经它们是如何相互作用的。人类的视觉系统是快速和准确的，使我们能够以很少的有意识的思考执行复杂的任务，如驾驶。快速，准确的目标检测算法可以让计算机在不用任何专用的传感器的情况下驾驶汽车，使辅助设备能够向人类用户传输实时场景信息，并解锁用于通用的、响应式的机器人系统的潜力。

目前的检测系统重新应用分类器来进行检测。为了检测一个目标，这些系统为该目标采用一个分类器，并在测试图像上的不同位置和尺度上使用它。像可变形的组件模型 (DPM) 这样的系统使用滑动窗口的方法，分类器在整个图像上均匀间隔的位置上运行。

最近的方法，如 R-CNN，使用区域候选方法首先在图像中生成潜在的边界框，然后在这些候选框上运行分类器。分类之后，使用后处理来细化边界框，消除重复的检测，并基于场景中的其他物体对边界框重新打分。这些复杂的流水线速度很慢并且难以优化，因为每个独立的组件必须单独训练。

我们将目标检测重新定义为一个单一的回归问题，直接从图像像素到边界框坐标和类别概率。使用我们的系统，你只需要看一次 (YOLO) 图像，就可以有什么物体以及它们在哪里。

YOLO 非常简单：参见图 1。一个卷积网络同时预测多个边界框以及这些边界框的类别概率。YOLO 在完整图像上训练，并直接优化检测性能。与传统目标检测方法相比，这个统一的模型有几个优势。

第一，YOLO 的速度非常快。由于我们将检测定义为回归问题，所以我们不需要一个复杂的流水线。我们只需要在测试时在新图像上运行我们的神经网络来预测检测结果。我们的基础网络在 Titan X GPU 上，没有批处理，以 45  帧/秒的速度运行，并且一个更快的版本超过每秒 150 帧。这意味着我们可以以小于 25 ms 的延迟处理流媒体视频。此外，YOLO 的平均精度是其他实时系统的两倍多。一个关于我们的系统在网络摄像头上实时运行的演示请参考我们的项目网页：http://pjreddie.com/yolo/ 。

第二，YOLO 