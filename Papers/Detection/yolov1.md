# [You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/pdf/1506.02640.pdf)

## Abstract

我们提出了 YOLO，一种新的目标检测方法。先前的目标检测工作重新应用 (repurposes) 分类器来进行检测。相反，我们将目标检测定义为一个关于空间上分离的边界框和相关类别的概率的回归问题。在一次评估中，单个神经网络直接从完整的图像预测边界框和类别概率。由于整个检测流水线 (pipeline) 是一个单一神经网络，因此可以在检测性能上直接进行端到端优化。

我们的统一架构非常快。我们的基础 YOLO 模型以 45 帧/秒的速度实时处理图像。该网络的一个更小的版本，Fast YOLO，能达到惊人的 155 帧/秒，同时仍然取得了其他实时检测器的两倍的 mAP。与其他最先进的检测系统相比，YOLO 产生更多的定位错误，但更少可能在背景区域上产生误报 (假阳)。最后，YOLO 学习目标的一般表示。当从自然图像推广到其他领域 (如艺术品) 时，它优于其他检测方法，包括 DPM 和 R-CNN。

## 1. Introduction

人们扫一眼图像就能立刻知道图像中有什么物体，它们在哪里，已经它们是如何相互作用的。人类的视觉系统是快速和准确的，使我们能够以很少的有意识的思考执行复杂的任务，如驾驶。快速，准确的目标检测算法可以让计算机在不用任何专用的传感器的情况下驾驶汽车，使辅助设备能够向人类用户传输实时场景信息，并解锁用于通用的、响应式的机器人系统的潜力。

目前的检测系统重新应用分类器来进行检测。为了检测一个目标，这些系统为该目标采用一个分类器，并在测试图像上的不同位置和尺度上使用它。像可变形的组件模型 (DPM) 这样的系统使用滑动窗口的方法，分类器在整个图像上均匀间隔的位置上运行。

最近的方法，如 R-CNN，使用区域候选方法首先在图像中生成潜在的边界框，然后在这些候选框上运行分类器。分类之后，使用后处理来细化边界框，消除重复的检测，并基于场景中的其他物体对边界框重新打分。这些复杂的流水线速度很慢并且难以优化，因为每个独立的组件必须单独训练。

我们将目标检测重新定义为一个单一的回归问题，直接从图像像素到边界框坐标和类别概率。使用我们的系统，你只需要看一次 (YOLO) 图像，就可以有什么物体以及它们在哪里。

YOLO 非常简单：参见图 1。一个卷积网络同时预测多个边界框以及这些边界框的类别概率。YOLO 在完整图像上训练，并直接优化检测性能。与传统目标检测方法相比，这个统一的模型有几个优势。

第一，YOLO 的速度非常快。由于我们将检测定义为回归问题，所以我们不需要一个复杂的流水线。我们只需要在测试时在新图像上运行我们的神经网络来预测检测结果。我们的基础网络在 Titan X GPU 上，没有批处理，以 45  帧/秒的速度运行，并且一个更快的版本超过每秒 150 帧。这意味着我们可以以小于 25 ms 的延迟处理流媒体视频。此外，YOLO 的平均精度是其他实时系统的两倍多。一个关于我们的系统在网络摄像头上实时运行的演示请参考我们的项目网页：http://pjreddie.com/yolo/ 。

第二，YOLO 在预测时会对图像进行全局地推理。与滑动窗口和基于区域候选的技术不同，YOLO 在训练和测试期间都是看整个图像的，因此它隐式地编码了关于类别以及它们的出现的上下文信息。Fast R-CNN，一种顶级的检测方法，将图像中背景块 (patches) 误认为目标，因为它无法看到更大的上下文。YOLO 产生的背景错误数量不到 Fast R-CNN 的一半。

第三，YOLO 学习的是物体的通用的表示。当在自然图像上训练并在艺术品上测试时，YOLO 的表现远远超过顶级检测方法，如 DPM 和 R-CNN。因为 YOLO 具有高度的泛化性，所以当它应用于新领域或意外的输入时，它不太可能会发生故障。

YOLO 在准确性方面仍然落后于最先进的检测系统。虽然它可以快速地识别图像中的目标，但它很难精确地定位一些目标，特别是小目标。我们在实验中进一步检验这些权衡。

我们所有的训练和测试代码都是开源的。各种预训练模型也是可以下载的。

## 2. Unified Detection

我们将目标检测的各个组件统一到一个单一的神经网络中。我们的网络使用整个图像的特征来预测每个边界框。它同时预测图像的所有类别的所有边界框。这意味着我们的网络对整个图像和图像中所有的物体进行全局地推理。YOLO 的设计使得端到端训练和实时并同时保持较高的平均精度成为可能。

我们的系统将输入图像划分为一个 $S \times S$ 的网格。如果一个物体的中心落在一个网格单元内，那么这个网格单元负责检测该物体。

每个网格单元预测 $B$ 个边界框和这些框的置信度分数。这些置信度分数反映了模型对框内包含一个物体的置信度，以及它认为它预测的框有多准确。我们正式地定义置信度为 $\rm Pr(Object) * IOU_{pred}^{truth}$ 。如果网格单元内不存在目标，置信度分数应该为零。否则，我们希望置信度分数等于预测框与真实框之间的交并比 (IOU)。

每个边界框包含 5 个预测值：$x, y, w, h$ 和 confidence。$(x, y)$ 坐标表示物体的中心，相对于网格单元边界的。预测的宽和高是相对于整个图像的。最后，置信度表示预测框和真实框之间的 IOU。













## 6. Conclusion

我们介绍了 YOLO， 一种统一的目标检测模型。我们的模型容易构建，并且能直接完整的图像上训练。于基于分类器的方法不同，YOLO 是在一个直接对应检测性能的损失函数上训练的，并且整个模型是联合训练的。

Fast YOLO 是文献中最快的通用的目标检测器，YOLO 在实时检测方面推动了最先进的技术水平。YOLO 还可以很好地推广到新的领域，使其成为那些依赖快速的、健壮的目标检测的应用的理想选择。