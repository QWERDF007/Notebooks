# [PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding](https://arxiv.org/abs/2312.04461)

## Abstract

最近的文本到图像生成技术取得了显著进展，可以根据给定的文本提示合成逼真的人类照片。然而，现有的个性化生成方法不能同时满足高效率、身份 (ID) 保真度高和灵活的文本可控性的要求。在这项工作中,我们提出了 PhotoMaker，一种高效的个性化文本到图像生成方法，它主要将任意数量的输入 ID 图像编码成堆叠的 ID 嵌入 (embedding) 以保留 ID 信息。这样的嵌入，作为统一的 ID 表示，不仅可以充分地封装同一输入 ID 的特征，还可以容纳不同 ID 的特征以进行后续集成。这为更有趣和实用的应用铺平了道路。此外，为了推动我们的 PhotoMaker 的训练，我们提出了一个以 ID 为导向的数据构建流水线来汇编训练数据。在通过所提出的流水线构建的数据集的帮助下，我们的 PhotoMaker 表现出比基于测试时间微调的方法更好的 ID 保留能力，同时提供了显著的速度改进、高质量的生成结果、强大的泛化能力和广泛的应用范围。

## 1. Introduction

人类相关的定制图像生成[28, 35, 51]引起了相当大的关注，催生了许多应用，例如个性化肖像照片1、图像动画[67]和虚拟试穿[59]。早期的方法[39, 41]由于生成模型 (即 GANs [19, 29]) 的能力有限，只能定制面部区域的生成，导致多样性、场景丰富性和可控性较低。得益于更大规模的文本图像配对训练数据集[55]、更大的生成模型[44, 52]以及可以提供更强语义嵌入的文本/视觉编码器[45, 46]，基于扩散的文本到图像生成模型最近不断发展。这种发展使它们能够生成越来越逼真的面部细节和丰富的场景。由于存在文本提示和结构指导[40, 65]，可控性也得到了很大提高。

同时，在强大的扩散文本到图像模型的培养下，许多基于扩散的定制生成算法[17, 50]已经出现，以满足用户对高质量定制结果的需求。在商业和社区应用中最广泛使用的是基于 DreamBooth 的方法[2, 50]。这些应用程序需要数十张相同身份 (ID) 的图像来微调模型参数。虽然生成的结果有很高的 ID 保真度，但有两个明显的缺点：一是每次用于微调的定制数据需要手动收集，因此非常耗时和费力；另一个是自定义每个 ID 需要10-30分钟，消耗大量计算资源，特别是当生成模型变大时。因此，为了简化和加速定制生成过程，近期的工作在现有以人为中心的数据集[29, 36]的驱动下，训练了视觉编码器[11, 62]或超网络[5, 51]来表示输入 ID 图像为嵌入或 LoRA [25]权重。训练后，用户只需要提供要定制的 ID 的图像，就可以通过几十步的微调甚至无需任何调优过程就可以实现个性化生成。然而，这些方法定制的结果在 ID 保真度和生成多样性方面无法同时具备 DreamBooth 的效果 (见图3)。这是因为：1) 在训练过程中，目标图像和输入 ID 图像都从同一图像中采样。训练后的模型很容易记住与 ID 无关的图像特征，如表情和视角，这导致可编辑性较差，2) 仅依赖单个要定制的ID图像，模型难以从其内部知识中辨别要生成的ID的特征，导致 ID 保真度不佳。