# [Deep Learning Tuning Playbook](https://github.com/google-research/tuning_playbook)



## 目录

- [这份文件适合谁?](#这份文件适合谁?)
- [为什么需要优化调校指南?](#为什么需要优化调校指南?)
- [新项目指南](#新项目指南):
  - [选择模型架构](#选择模型架构)
  - [选择优化器](#选择优化器)
  - [选择批量大小](#选择批量大小)
  - [选择初始配置](#选择初始配置)
- [提高模型性能的科学方法](#提高模型性能的科学方法):
  - 增量调优策略
  - 探索与利用权衡
  - 如何选择下一轮实验的目标
  - 如何设计下一轮实验
  - 如何决定是否采用某项训练流程改进或超参数配置
  - 探索结束后的考量
- 如何确定每个训练运行的步数:
  - 当训练不受计算资源限制时的决策
  - 当训练受计算资源限制时的决策
- 训练流程的附加指导:
  - 如何优化输入流程
  - 如何评估模型性能
  - 如何保存检查点并选择最佳检查点
  - 如何设置实验跟踪
  - 批标准化的实现细节
  - 多主机流程的注意事项
- 常见问题
- 鸣谢
- 引用
- 贡献



## 这份文件适合谁?

这份文件适用于那些有兴趣**最大化深度学习模型性能**的工程师和研究人员(个人和团队)。我们假设读者已了解机器学习和深度学习的基本概念。

我们强调的是**超参数调优过程**。我们会涉及深度学习训练的其他方面,例如流程实现和优化,但我们对这些方面的讨论并不打算做到全面。

我们假设机器学习问题是一个监督学习问题,或者与监督学习问题非常相似(例如自监督)。也就是说,本文中的一些建议可能也适用于其他类型的问题。

## 为什么需要优化调校指南?

目前，让深度神经网络在实践中真正发挥作用需要付出惊人的努力和大量的猜测。更糟糕的是，人们用来获得良好深度学习结果的实际方法很少被记录下来。论文为了呈现更简洁的故事，往往会忽略导致最终结果的过程，而商业问题上工作的机器学习工程师很少有时间退一步总结他们的方法。即使作者拥有应用方面的丰富经验并能提供实用的建议，教科书也倾向于回避实用指南，而优先考虑基本原理。在准备创建这份文档时，我们找不到任何试图真正解释如何使用深度学习获得良好结果的综合尝试。相反，我们发现了一些零散的建议散落在博客文章和社交媒体上，研究论文附录中零星的技巧，偶尔关于某个特定项目或流程的案例研究，以及大量的困惑。深度学习专家与不太熟练的实践者使用表面上相似的方法取得的结果之间存在巨大差距。同时，这些专家也 readily 承认他们所做的一些事情可能缺乏充分的理由。随着深度学习的成熟及其对世界的影响越来越大，社区需要更多涵盖实用方法的资源，包括所有对获得良好结果至关重要的实际细节。

我们是一个由五名研究人员和工程师组成的团队，已经在深度学习领域工作多年，有些人早在 2006 年就开始从事这项工作。我们已经将深度学习应用于从语音识别到天文学等各种问题，并在此过程中学到了很多东西。这份文档源于我们自己训练神经网络、教授新机器学习工程师以及指导同事进行深度学习实践的经验。虽然看到深度学习从少数学术实验室的一种机器学习方法发展成为数十亿人使用的产品背后的技术让人欣慰，但深度学习作为一门工程学科仍然处于起步阶段，我们希望这份文档能鼓励其他人帮助系统化该领域的实验协议。

这份文档的产生源于我们试图总结我们自己对深度学习的方法，因此它代表了作者在写作时的观点，而不是任何客观的真理。我们自己与超参数调优的斗争使之成为我们指导的特别关注点，但我们也涵盖了我们在工作中遇到的其他重要问题 (或看到过的问题) 。我们的目标是让这份工作成为一份不断成长和演变的活文档，随着我们的观点改变而发展。例如，关于调试和减轻训练失败的材料，我们两年前是无法撰写的，因为它基于最近的结果和正在进行的调查。不可避免地，我们的一些建议需要根据新的结果和改进的工作流程进行更新。我们不知道最佳的深度学习配方，但除非社区开始记录和辩论不同的程序，否则我们无法找到它。为此，我们鼓励发现我们建议有问题的人提出替代建议，并提供令人信服的证据，以便我们更新指南。我们还很乐意看到可能有不同建议的替代指南和 playbook，以便我们作为一个社区共同努力朝着最佳实践迈进。最后，任何标有 🤖 表情符号的部分都是我们希望做更多研究的地方。只有在尝试编写这份指南之后，我们才完全清楚深度学习实践者的工作流程中存在着多少有趣且被忽视的研究问题。

## 新项目指南

我们在调参过程中做出的许多决策可以仅在项目开始时制定一次，只有在情况发生变化时才会偶尔重新审视。

以下我们的指导假设如下：

- 问题表述、数据清洗等基本工作已经完成，花时间研究模型架构和训练配置是合理的。
- 已经建立了一个用于训练和评估的管道，可以方便地执行感兴趣的不同模型的训练和预测任务。
- 已经选择了合适的评估指标并实现了它们。这些指标应尽可能代表部署环境中将测量的指标。

我们在调优过程中做出的许多决策可以在项目开始时一次性做出,只有在情况发生变化时才偶尔重新审视。

### 选择模型架构

**总结**：新项目应当尽量先采用已经奏效的模型结构。

- 选择一个成熟的、常用的模型架构，先让它工作起来。以后总是可以建立一个自定义的模型。

- 模型架构通常有各种超参数来确定模型的大小和其他细节 (例如层数、层宽度、激活函数类型)。

    - 因此，选择架构实际上意味着选择一系列不同的模型 (每个模型对应模型超参数的一种设置)。
    
    - 我们将在[如何选择初始配置](#如何选择初始配置)和[提高模型性能的科学方法](#提高模型性能的科学方法)部分考虑选择模型超参数的问题。

- 尽可能找到一篇与您要解决的问题非常接近的论文，并复制该模型作为起点。

### 选择优化器

**总结**：从最适合手头问题类型的最常用的优化器开始。

- 没有一种万能的优化器适用于所有机器学习问题和模型架构。即使只是[比较优化器的性能也是一项困难的任务](https://arxiv.org/abs/1910.05446)。🤖

- 我们建议坚持使用成熟的、流行的优化器，特别是在启动一个新项目时。

    - 最理想的是选择与同类型问题中最为流行的优化器。

- 做好准备关注所选择优化器的**所有**超参数。

    - 超参数更多的优化器可能需要更多调优工作来找到最佳配置。
    
    - 这在项目初期尤其重要，因为我们首先试图在将优化器超参数视为[无关参数](#识别什么是科学的超参数、冗余的超参数和固定的超参数)的同时找到各种其他超参数 (例如架构超参数) 的最佳值。
    
    - 在项目的初始阶段，启动一个更简单的优化器 (例如固定动量的 SGD 或固定 β、β1 和 β2 的 Adam) 可能更可取，之后再切换到一个更通用的优化器。

- 我们喜欢的成熟的优化器包括 (但不限于):

    - [带动量的 SGD](#目前流行的优化算法的更新规则是什么？) (我们喜欢 Nesterov 变体)

    - 比带动量 SGD 更通用的 [Adam 和 NAdam](目前流行的优化算法的更新规则是什么？)。注意 Adam 有 4 个可调超参数，[它们都很重要](https://arxiv.org/abs/1910.05446)!

        - 参见[应该如何调整Adam的超参数?](#应该如何调整Adam的超参数?)

### 选择批量大小

**总结**：批处理大小决定了训练速度，不应直接用于调整验证集性能。通常，理想的批量大小将是可用硬件支持的最大批量大小。

- 批量大小是决定训练时间和计算资源消耗的一个关键因素。
- 增加批量大小通常可以减少训练时间。这可能非常有益，例如:

  - 在固定的时间间隔内更彻底地调优超参数，从而可能得到更好的最终模型。

  - 减少开发周期的延迟，允许更频繁地测试新想法。

- 增加批量大小可能会降低、提高或不改变资源消耗。
- 批处理大小不应该被视为用于调整验证集性能的可调超参数。

  - 只要所有超参数调优良好 (特别是学习率和正则化超参数) 且训练步数足够，应该可以用任何批量大小获得相同的最终性能 (参见 [Shallue et al. 2018](https://arxiv.org/abs/1811.03600))。

  - 请参阅[为什么不应该调整批量大小来直接提高验证集性能?](#为什么不应该调整批量大小来直接提高验证集性能?)

#### 确定可行的批量大小和估计训练吞吐量

<details><summary><em>[Click to expand]</em></summary>
<br>

- 对于给定的模型和优化器，可用硬件通常会支持一定范围内的批量大小。限制因素通常是加速器 (例如 GPU) 内存。
- 不幸的是，在不运行或至少不编译完整的训练程序的情况下，很难计算哪些批量大小适合内存。
- 最简单的解决方案通常是以不同的批量大小 (例如递增的 2 的幂) 运行训练作业几个 steps，直到某个作业超过可用内存。
- 对于每个批量大小，我们应该训练足够长的时间以得到训练吞吐量的可靠估计：

<p align="center">训练吞吐量 = (每秒处理的示例数)</p>

<p align="center">或等价地, <em>每个 step 时间</em>.</p>

<p align="center">每个 step 时间 = (批量大小) / (训练吞吐量)</p>

- 当加速器还未饱和时，如果批量大小加倍，训练吞吐量也应该加倍 (或至少近乎加倍)。等价地，随着批量大小的增加，每步时间应该是常量 (或近乎常量)。
- 如果不是这种情况，则训练流程存在瓶颈，如 I/O 或计算节点之间的同步。在继续之前，这可能值得诊断和纠正。
- 如果训练吞吐量仅增加到某个最大批量大小，那么我们应该只考虑该最大批量大小以下的批量大小，即使硬件支持更大的批量大小。
  - 使用更大批量大小的所有好处都假定训练吞吐量增加。如果没有增加，则解决瓶颈问题或使用更小的批量大小。
  - **梯度累积 (Gradient accumulation)** 能够模拟比硬件所能支持的更大的批量大小，但不提供任何吞吐量优势。在应用工作中通常应该避免使用。
- 每当模型或优化器发生变化时，可能需要重复这些步骤 (例如不同的模型架构可能允许更大的批量大小以适应内存)。

</details>

#### 选择合适的批量大小以减少训练时间

<details><summary><em>[Click to expand]</em></summary>
<br>

<p align="center">训练时间 = 每步时间 x 总步数</p>

- 我们通常可以认为每步时间 (time per step) 对于所有可行的批量大小来说都是近似恒定的。当没有并行计算的开销且所有训练瓶颈都已被诊断和纠正时，这是真的 (见[上一节](#确定可行的批量大小和估计训练吞吐量)中关于如何识别训练瓶颈的内容)。在实践中，增加批量大小通常至少会有一些开销。
- 随着批量大小的增大，达到固定性能目标所需的总步数数通常会减少 (前提是在改变批量大小时重新调整所有相关的超参数；[Shallue et al, 2018](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1811.03600)) 。
  - 例如，将批量大小加倍可能会使所需总步数减少一半。这被称为**完美缩放**。
  - 完美缩放对所有批量大小都成立，直到到达一个临界值，超过这个阈值，再调整批量大小就会出现收益递减。
  - 最终，增加批量大小不能再减少训练步数了 (但也绝不会增加) 。
- 因此，使训练时间最小化的批量大小通常是能够缩减所需训练步数的批量大小的最大值。
  - 这个值取决于数据集、模型和优化器，除了通过实验为每个新问题找到它之外，如何计算它仍然是一个悬而未决的问题。
  - 在比较批量大小时，要注意**样本预算 (example budget)** / **epoch 预算** (在固定训练样本数量的情况下运行所有实验) 和**步数预算 (step budget)** (在固定训练步数的情况下运行所有实验) 之间的区别。
    - 仅使用 epoch 预算比较批量大小只会探测完美缩放机制，即使更大的批量大小仍然可以通过减少所需的训练步数来提供显着的速度提升。
  - 通常，可用硬件支持的最大批量大小将小于关键批量大小。 因此，**一个好的经验法则 (无需运行任何实验) 是使用尽可能大的批量大小**。
- 如果最终增加训练时间，则使用更大的批量大小毫无意义。

</details>

#### 选择合适的批量大小以减少资源消耗

<details><summary><em>[Click to expand]</em></summary>
<br>

- 有两种类型的资源成本与增加批量大小有关。
  
  1. 前期成本 (Upfront costs)，例如，购买新硬件或重写训练管道以实现多 GPU / 多 TPU 训练。
  2. 使用成本 (Usage costs)，例如，根据团队的资源预算计费，来自云供应商处计费，电力/维护成本。
- 如果增加批量大小的前期成本很高，那么最好推迟增加批量大小，直到项目成熟并且更容易评估成本效益权衡为止。 实现多主机并行训练程序可能会引入[错误](#多主机管道的注意事项)和[难以察觉的问题](#批量标准化的实现细节)，因此从更简单的管道开始可能更好。(另一方面，在需要大量调参实验的早期阶段，训练时间的大幅缩短可能会非常有利。)
- 我们将总使用成本 (可能包含多种不同类型的成本) 称为“资源消耗”。我们可以将资源消耗分解为以下部分：

<p align="center">资源消耗 = (每个步骤的资源消耗) x (总步数)</p>

- 增加批量大小通常可以让我们[减少总步数](#选择合适的批量大小以减少训练时间)。资源消耗是增加还是减少将取决于每个步骤的消耗如何变化。
  - 增加批量大小可能会减少资源消耗。例如，如果使用更大批量大小的每个步骤都可以在与较小批量大小相同的硬件上运行（仅需少量增加每个步骤的时间），那么每个步骤的资源消耗增加可能会被步数的减少所抵消。
  - 增加批量大小可能不会改变资源消耗。例如，如果将批量大小加倍会使所需步数减少一半，并且使使用的 GPU 数量增加一倍，那么总消耗（以 GPU-小时计）将不会改变。
  - 增加批量大小可能会增加资源消耗。例如，如果增加批量大小需要升级硬件，则每个步骤的消耗增加可能会超过步数的减少。

</details>

#### 改变批量大小需要重新调整大多数参数

<details><summary><em>[Click to expand]</em></summary>
<br>

- 大多数超参数的最佳值会受到批量大小的影响。因此，更改批量大小通常需要从头开始重新进行调参过程。
- 与批量大小交互最强烈的超参数是优化器超参数（例如学习率、动量）和正则化超参数，因此对于每个批量大小单独调整最重要。
- 在项目开始时选择批量大小时请记住这一点。如果您稍后需要切换到不同的批量大小，那么重新调整所有内容以适应新批量大小可能很困难、耗时且成本高昂。

</details>

#### 批量标准化如何与批量大小交互

<details><summary><em>[Click to expand]</em></summary>
<br>
批量标准化比较复杂，通常应该使用不同于梯度计算的批量大小来计算统计信息。有关详细信息，请参阅[批量标准化](#批量标准化的实现细节)部分。

</details>

### 选择初始配置

- 在开始调参之前，我们必须确定起点。这包括指定 (1) 模型配置（例如层数），(2) 优化器超参数（例如学习率），以及 (3) 训练步数。
- 确定初始配置需要一些手动配置的训练运行和反复试验。
- 我们的指导原则是找到一个简单、运行较快、资源消耗较低的配置，以获得“合理”的结果。
  - “简单”意味着尽可能避免使用花里胡哨的技巧；这些功能以后都可以添加。即使花里胡哨的功能在以后被证明有用，在初始配置中添加它们也可能会浪费时间来调整无用的功能和/或引入不必要的复杂性。
    - 例如，在添加花哨的衰减调度程序之前，先从恒定学习率开始。
  - 选择一个运行速度快、资源消耗最少的初始配置将使调参更加高效。
    - 例如，从较小的模型开始。
  - “合理”的性能取决于具体问题，但至少意味着训练后的模型在验证集上的表现远优于随机猜测（尽管它可能糟糕到不值得部署）。
- 选择训练步数需要平衡以下因素：
  - 一方面，训练更多步数可以提高性能并简化调参（请参阅 Shallue et al. 2018）。
  - 另一方面，训练更少的步数意味着每次训练运行都更快，并且使用的资源更少，通过减少循环之间的时间并允许并行运行更多实验来提高调参效率。此外，如果最初选择不必要的大步数，以后可能很难更改它，例如，一旦学习率调度程序针对该步数进行调整。

## 提高模型性能的科学方法

在这份文档中，机器学习开发的最终目标是最大化部署模型的效用。尽管开发过程的许多方面因应用程序而异（例如时间长度、可用计算资源、模型类型），但我们通常可以在任何问题上使用相同的的基本步骤和原则。

以下我们的指导假设如下：

- 已经拥有一个完整的训练管道以及可以获得合理结果的配置。
- 有足够的计算资源来进行有意义的调参实验和并行运行至少几个训练作业。

### 增量式调参策略

**总结**：从简单的配置开始，逐步改进，同时深入理解问题。确保任何改进都基于强有力的证据，以避免增加不必要的复杂性。

- 我们的最终目标是找到一个配置来最大化我们模型的性能。

  - 在某些情况下，我们的目标是在固定期限内尽可能多地改进模型（例如，参加比赛）。
  - 在其他情况下，我们希望无限期地改进模型（例如，不断改进生产中使用的模型）。

- 原则上，我们可以通过使用算法自动搜索所有可能的配置空间来最大化性能，但这并不是一个实用的选择。

  - 可能的配置空间非常大，目前还没有足够复杂的算法可以在没有人工指导的情况下高效地搜索这个空间。

- 大多数自动搜索算法依赖于手动设计的搜索空间，该搜索空间定义了要搜索的配置集，这些搜索空间可能非常重要。
  
- 最大化性能最有效的方法是从一个简单的配置开始，逐步添加功能并进行改进，同时深入理解问题。
  
  - 我们在每一次调参中使用自动搜索算法，并随着理解的加深不断更新我们的搜索空间。

- 随着探索的进行，我们自然会找到越来越好的配置，因此我们“最佳”的模型将不断改进。
  
  - 当我们更新最佳配置（可能对应实际生产模型的启动，也可能不对应）时，我们称之为“发布”。
  - 对于每次发布，我们都必须确保更改基于强有力的证据 - 不仅仅是基于幸运配置的随机猜测 - 以免增加训练管道的不必要的复杂性。

总而言之，我们的增量式调参策略涉及重复以下四个步骤：

1. 为下一轮实验确定一个适当范围的目标。
2. 设计并运行一系列实验，朝着这个目标取得进展。
3. 从结果中学习我们可以学到的东西。
4. 考虑是否启动新的最佳配置。

本节剩余部分将更详细地讨论此策略。

### 探索 vs 利用

 **总结：**大多数时候，我们的主要目标是深入理解问题。

- 人们可能会认为我们会花费大部分时间尝试优化验证集性能，但实际上，我们大部分时间都花在理解问题上，很少时间专注于验证误差。

  - 换句话说，我们花更多时间在“探索”上，更少时间在“利用”上。

- 从长远来看，理解问题对于最终性能提升至关重要。优先考虑洞察力而不是短期收益可以帮助我们：
  
  - 避免因偶然因素出现在高性能运行中的无关更改而发布该更改。
  - 识别验证误差最敏感的超参数、交互最多的超参数（需要一起重新调整），以及对其他更改不敏感的超参数（可以在以后的实验中固定）。
  - 提出尝试新功能的可能性，例如在过拟合问题上尝试新的正则化项。
  - 识别无用的特征并删除它们，降低未来实验的复杂性。
  - 识别来自超参数调整的改进何时可能已经饱和。
  - 将搜索空间缩小到最佳值附近以提高调参效率。

- 当我们准备好利用时，即使实验不能最大程度地提供有关调整问题结构的信息，我们也可以纯粹关注验证错误。

  

  

  

## 常见问题

### 最好的学习率衰减计划族是什么？

<details><summary><em>[Click to expand]</em></summary>
<br>

- 这仍是一个开放问题。目前还不清楚如何构建一组严格的实验来可靠地回答什么是“最佳”的学习率衰减计划。
- 尽管我们不知道最佳的计划族,但我们确信拥有某种(非常量)计划并对其进行调优是很重要的。
- 在优化过程的不同时间,不同的学习率效果最佳。采用某种计划可以增加模型达到良好学习率的可能性。

</details>



### 目前流行的优化算法的更新规则是什么？



### 应该如何调整Adam的超参数?



### 为什么不应该调整批量大小来直接提高验证集性能?





## 提高模型性能的科学方法

### 如何设计下一轮实验

#### 识别什么是科学的超参数、冗余的超参数和固定的超参数



