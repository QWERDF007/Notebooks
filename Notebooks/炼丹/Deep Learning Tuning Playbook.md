# [Deep Learning Tuning Playbook](https://github.com/google-research/tuning_playbook)



## 目录

- [这份文件适合谁?](#这份文件适合谁?)
- [为什么需要优化调校指南?](#为什么需要优化调校指南?)
- [新项目指南](#新项目指南):
  - [选择模型架构](#选择模型架构)
  - [选择优化器](#选择优化器)
  - [选择批量大小](#选择批量大小)
  - [选择初始配置](#选择初始配置)
- 提高模型性能的科学方法:
  - 增量调优策略
  - 探索与利用权衡
  - 如何选择下一轮实验的目标
  - 如何设计下一轮实验
  - 如何决定是否采用某项训练流程改进或超参数配置
  - 探索结束后的考量
- 如何确定每个训练运行的步数:
  - 当训练不受计算资源限制时的决策
  - 当训练受计算资源限制时的决策
- 训练流程的附加指导:
  - 如何优化输入流程
  - 如何评估模型性能
  - 如何保存检查点并选择最佳检查点
  - 如何设置实验跟踪
  - 批标准化的实现细节
  - 多主机流程的注意事项
- 常见问题
- 鸣谢
- 引用
- 贡献



## 这份文件适合谁?

这份文件适用于那些有兴趣**最大化深度学习模型性能**的工程师和研究人员(个人和团队)。我们假设读者已了解机器学习和深度学习的基本概念。

我们强调的是**超参数调优过程**。我们会涉及深度学习训练的其他方面,例如流程实现和优化,但我们对这些方面的讨论并不打算做到全面。

我们假设机器学习问题是一个监督学习问题,或者与监督学习问题非常相似(例如自监督)。也就是说,本文中的一些建议可能也适用于其他类型的问题。

## 为什么需要优化调校指南?

目前,想要深度神经网络得到良好的实际效果,需要付出惊人的努力和猜测。更糟糕的是,人们用深度学习获得良好结果的实际方案极少被记录。论文通常会略过导致最终结果的过程,以呈现更简洁的故事,而从事商业问题的机器学习工程师通常没有时间退一步并概括他们的过程。教科书倾向于避免实用指导,优先考虑基本原则,即使作者有提供实用建议所需的应用经验。在准备编写此文档时,我们找不到任何全面解释“如何用深度学习获得良好结果”的尝试。相反,我们在博客文章和社交媒体上找到了一些建议的片段,在研究论文的附录中瞥见的技巧,关于某个项目或流程的个案研究,以及大量的困惑。深度学习专家和使用表面相似方法的不那么熟练的从业者之间取得的结果存在巨大差距。与此同时,这些专家自己也容易认同他们所做的一些事情可能不太有根据。随着深度学习的成熟和其对世界的更大影响,社区需要更多关于有用方案的资源,包括对获得良好结果至关重要的所有实际细节。

我们是一支由五名研究人员和工程师组成的团队,我们从事深度学习已有多年,有些人早在2006年就开始了。我们将深度学习应用于从语音识别到天文学等各种问题,在这个过程中学到了很多。本文档源于我们自己训练神经网络、指导新机器学习工程师以及就深度学习实践向同事提供建议的经验。虽然看到深度学习从少数学术实验室的一种机器学习方法发展成为数十亿人使用的产品背后的技术让人欣慰,但作为一门工程学科,深度学习仍处于萌芽阶段,我们希望这份文件能鼓励其他人帮助系统化该领域的实验方案。

本文档诞生于我们试图总结自己的深度学习方法,因此它代表了撰写时作者的观点,而不是任何客观真理。超参数调优方面的艰难使其成为我们指导的重点,但我们还涵盖了在工作中遇到的其他重要问题(或看到出错的问题)。我们的目的是让这份工作成为一个随着我们观点变化而生长和发展的动态文件。例如,关于调试和缓解训练失败的材料两年前是我们无法撰写的,因为它基于最近的结果和正在进行的调查。不可避免地,我们的一些建议将需要更新,以解释新的结果和改进的工作流程。我们不知道深度学习的最佳方案,但是在社区开始书写和辩论不同的程序之前,我们不能指望找到它。为此,我们鼓励读者对我们的建议提出异议,提供替代建议以及令人信服的证据,以便我们可以更新该实践指南。我们也很乐意看到具有不同建议的替代指南,以便我们作为一个社区可以努力确定最佳实践。最后,标有🤖表情符号的任何章节都是我们希望做更多研究的地方。仅在试图编写此实践指南后,我们才完全明白深度学习从业者的工作流程中可以找到多少有趣且被忽略的研究问题。

## 新项目指南

我们在调优过程中做出的许多决策可以在项目开始时一次性做出,只有在情况发生变化时才偶尔重新审视。

我们下面的指导意见基于以下假设:

*   已经完成了问题建模、数据清洗等必要工作,因此花时间在模型架构和训练配置上才是有意义的。

*   已经建立了进行训练和评估的流程,并且可以轻松地为各种感兴趣的模型执行训练和预测作业。

*   已经选择和实现了适当的指标。这些指标应该尽可能代表部署环境中会测量的内容。

### 选择模型架构

**总结:** 新项目应当尽量先采用已经奏效的模型结构。

- 选择一个成熟的、常用的模型架构，先让它工作起来。以后总是可以建立一个自定义的模型。

- 模型架构通常有各种超参数来确定模型的大小和其他细节(例如层数、层宽度、激活函数类型)。

    - 因此,选择架构实际上意味着选择一个不同的模型系列(每个模型对应模型超参数的一种设置)。
    
    - 我们将在[如何选择初始配置](#如何选择初始配置)和[提高模型性能的科学方法](#提高模型性能的科学方法)部分考虑选择模型超参数的问题。

- 如果可能,尝试找到一篇解决尽可能接近手头问题的论文,并复现其中的模型作为起点。

### 选择优化器

**总结:** 从最适合手头问题类型的最流行优化器开始。

- 没有一个优化器可以跨所有类型的机器学习问题和模型架构中表现最好。即使只是[比较优化器的性能也是一项困难的任务](https://arxiv.org/abs/1910.05446)。🤖

- 我们建议坚持使用成熟的、流行的优化器,特别是在启动一个新项目时。

    - 最理想的是选择与同类型问题中最为流行的优化器。

- 做好准备关注所选择优化器的**所有**超参数。

    - 超参数更多的优化器可能需要更多调优工作来找到最佳配置。
    
    - 这在项目初期尤其重要,因为我们首先试图在将优化器超参数视为[无关参数](#识别什么是科学的超参数、冗余的超参数和固定的超参数)的同时找到各种其他超参数(例如架构超参数)的最佳值。
    
    - 在项目的初始阶段,启动一个更简单的优化器 (例如固定动量的 SGD 或固定 β、β1 和 β2 的 Adam) 可能更可取,之后再切换到一个更通用的优化器。

- 我们喜欢的成熟的优化器包括(但不限于):

    - [带动量的 SGD](#目前流行的优化算法的更新规则是什么？) (我们喜欢 Nesterov 变体)

    - 比带动量SGD更通用的 [Adam 和 NAdam](目前流行的优化算法的更新规则是什么？)。注意 Adam 有 4 个可调超参数,[它们都很重要](https://arxiv.org/abs/1910.05446)!

        - 参见[应该如何调整Adam的超参数?](#应该如何调整Adam的超参数?)

### 选择批量大小

**总结:** 批量大小决定了训练速度,不应该被直接用来调优验证集性能。通常,理想的批量大小将是可用硬件所支持的最大批量大小。

- 批量大小是决定训练时间和计算资源消耗的一个关键因素。

- 增加批量大小通常可以减少训练时间。这可能非常有益,例如:

  - 在固定的时间间隔内更彻底地调优超参数,可能导致更好的最终模型。

  - 减少开发周期的延迟,允许更频繁地测试新想法。

- 增加批量大小可能会降低、提高或不改变资源消耗。

- 批量大小不应被视为可调超参数来提高验证集性能。

  - 只要所有超参数调优良好 (特别是学习率和正则化超参数) 且训练步数足够,应该可以用任何批量大小获得相同的最终性能 (参见 [Shallue et al. 2018](https://arxiv.org/abs/1811.03600))。

  - 请参阅[为什么不应该调整批量大小来直接提高验证集性能?](#为什么不应该调整批量大小来直接提高验证集性能?)

#### 确定可行的批量大小和估计训练吞吐量

<details><summary><em>[Click to expand]</em></summary>
<br>

- 对于给定的模型和优化器,可用硬件通常会支持一定范围内的批量大小。限制因素通常是加速器 (例如 GPU) 内存。
- 不幸的是,在不运行或至少不编译完整的训练程序的情况下,很难计算哪些批量大小适合内存。
- 最简单的解决方案通常是以不同的批量大小(例如递增的2的幂)运行训练作业几个 steps,直到某个作业超过可用内存。
- 对于每个批量大小,我们应该训练足够长的时间以得到训练吞吐量的可靠估计:

<p align="center">训练吞吐量 = (每秒处理的示例数)</p>

<p align="center">或等价地, <em>每个step时间</em>.</p>

<p align="center">每个step时间 = (批量大小) / (训练吞吐量)</p>

- 当加速器还未饱和时,如果批量大小加倍,训练吞吐量也应该加倍(或至少近乎加倍)。等价地,随着批量大小的增加,每步时间应该是常量(或近乎常量)。
- 如果不是这种情况,则训练流程存在瓶颈,如I/O或计算节点之间的同步。在继续之前,这可能值得诊断和纠正。
- 选用具有最大训练吞吐量的batch size，即使硬件支持更大的batch size。
  - 使用更大批量大小的所有好处都假定训练吞吐量增加。如果没有增加,则解决瓶颈问题或使用更小的批量大小。
  - **梯度累积 (Gradient accumulation)** 能够模拟比硬件所能支持的更大的批量大小,但不提供任何吞吐量优势。在应用工作中通常应该避免使用。
- 每当模型或优化器发生变化时,可能需要重复这些步骤 (例如不同的模型架构可能允许更大的批量大小以适应内存)。

</details>

#### 选择合适的批量大小以减少训练时间

<details><summary><em>[Click to expand]</em></summary>
<br>

<p align="center">训练时间 = 每步时间 x 总步数</p>

- 我们通常可以认为每步时间 (time per step) 对于所有可行的批量大小来说都是近似恒定的。当没有并行计算的开销且所有训练瓶颈都已被诊断和纠正时，这是真的 (见[上一节](#确定可行的批量大小和估计训练吞吐量)中关于如何识别训练瓶颈的内容)。在实践中，增加批量大小通常至少会有一些开销。
- 随着批量大小的增大，达到固定性能目标所需的总步数数通常会减少（前提是在改变批量大小时重新调整所有相关的超参数；[Shallue et al, 2018](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1811.03600)）。
  - 例如,加倍批量大小可能使所需总步数减半。这被称为**完美缩放**。
  - 完美缩放对所有批量大小都成立，直到到达一个临界值，超过这个阈值，再调整批量大小就会出现收益递减。
  - 最终，增加批量大小不能再减少训练步数了（但也绝不会增加）。

- 因此，使训练时间最小化的批量大小通常是能够缩减所需训练步数的批量大小的最大值。
  - 这个值取决于数据集、模型和优化器，除了通过实验为每个新问题找到它之外，如何把它计算出来是一个公开的问题。
  - 在比较批量大小时，要注意**样本预算 (example budget)** / **epoch 预算**（在固定训练样本数量的情况下运行所有实验）和**步骤预算step budget**（在固定训练**步骤**数量的情况下运行所有实验）之间的区别。


</details>

## 常见问题

### 最好的学习率衰减计划族是什么？

<details><summary><em>[Click to expand]</em></summary>
<br>

- 这仍是一个开放问题。目前还不清楚如何构建一组严格的实验来可靠地回答什么是“最佳”的学习率衰减计划。
- 尽管我们不知道最佳的计划族,但我们确信拥有某种(非常量)计划并对其进行调优是很重要的。
- 在优化过程的不同时间,不同的学习率效果最佳。采用某种计划可以增加模型达到良好学习率的可能性。

</details>



### 目前流行的优化算法的更新规则是什么？



### 应该如何调整Adam的超参数?



### 为什么不应该调整批量大小来直接提高验证集性能?





## 提高模型性能的科学方法

### 如何设计下一轮实验

#### 识别什么是科学的超参数、冗余的超参数和固定的超参数



