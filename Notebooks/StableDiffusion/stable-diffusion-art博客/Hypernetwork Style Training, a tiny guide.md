# [Hypernetwork Style Training, a tiny guide](https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/2670)

# 训练技巧

Prep：

- 选择好的图片，质量胜过数量
- 在 $512 \times 512$ 上训练，其他都会失真 (因为底模型是 $512 \times 512$ 的，sd 2.1 有提供 $768 \times 768$ 分辨率的模型)
- 使用 BILP 和/或 deepbooru 创建标签 (反推文本 prompt，一般千奇百怪的图用这些创建标签就没用，标签完全不搭边)
- 对于激活和初始化，查看[这里](# 激活和初始化)
- 对于网络大小，查看[这里](https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/2670#discussioncomment-4010316)

训练：

- 学习率：`5e-5:100, 5e-6:1500, 5e-7:10000, 5e-8:20000`
- 提示词模板：一个只有 `[filewords]` 的 txt 文件
- Steps：20000 或更少应该够了

长一点的解释：

- 选择好的图像，质量胜于数量
  我训练最好的模型是使用 21 张图像完成的。请记住，超网络风格迁移高度依赖于内容。如果你选择一个只画城市景观的艺术家，然后让 AI 生成一个具有他风格的角色，它可能不会给出你期望的结果。==超网络截取了训练时使用的词，所以如果没有描述字符的词，它就不知道该怎么办了==。它可能有效，也可能无效。

- 在 $512 \times 512$ 中训练，其他任何东西都会增加失真
  我已经测试过好几次了。我还没有从中得到好的结果。所以由你决定。

- 学习率：`5e-5:100, 5e-6:1500, 5e-7:10000, 5e-8:20000`
  几天前他们添加了一个训练调度器。我见过有人推荐快速训练等等。好吧，就是这样。这个时间表使用起来很安全。我还没有一个模型以这样的速度变坏，如果你让它达到 20000，它会捕捉到艺术/风格的更精细的细节。

- 提示模板：一个只有 `[filewords]` 的 .txt。
  如果你的 blip/booru 标签是正确的，这就是你所需要的。如果你想从你正在使用的模型中删除照片/艺术/等偏见，你可能想使用常规的超网络 txt 文件。由你决定。

- Steps：20000 或更少应该够了

  在我的学习率计划在里 5000-10000 范围内就可用。但是您会注意到，在 10000-20000 范围内，会显示出许多更精细的细节。

最后的笔记：

- 如果您的模型使用 VAE，请保持打开状态。不知道这是否会对训练产生影响，但只是确定一下。
- 卸载任何其他超网络。我不确定它是否会干扰训练，但安全起见。
- 如果你的模型坏了并且预览测试显示了五颜六色的噪音，不要只是倒退一点，选择一个更早的模型继续训练并进一步降低学习率。
- 不要中途更改训练数据，最好重新开始。
- 如果你的损失超过 0.3，你搞砸了并且可能破坏了你的超网络，降低学习率。



# 激活和初始化

这是一个关于激活方法、选项、初始化以及训练时选择什么的小指南。

## 可选项

- Normalization

  它试图将神经元权重保持在一个固定点周围。通常是通过从权重中减去标准差来实现的。它并不能真正避免您在训练中可能遇到的问题，但它可以让它们更长时间地保持在正常的状态，特别是 blowouts 神经元。

  当您的超网络在你的训练数据的崩坏速度过快且难以应对时，您应该使用它。坏处是，它使训练速度慢了 10%-20%。如果您正在使用 Kaiming He 初始化，则必须使用。

  编辑：检查代码后，它将归一化添加到网络的每一层中。这是低效的，应该是全局的或仅添加到输出层或最后一个隐藏层。

- Dropout

  尝试通过在每一步随机失活一定比例的神经元来使神经网络稀疏。上次我看了它在代码中设置为 30%。因此，这意味着您的超网络可以存储的数据减少 30%，但它也会迫使神经元进行弥补，并有可能继续学习并避免一些陷阱，例如死神经元、blowouts 和消失点。它完全是可选的，你的超网络越大，你就越有能力使用它，它在训练过程中就越有用。

  [stable-diffusion-webui/modules/hypernetworks/hypernetwork.py](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/d699720254365069866eafcdc519743664075a6d/modules/hypernetworks/hypernetwork.py#L65)

  ```python
   linears.append(torch.nn.Dropout(p=0.3)) 
  ```

## 初始化

- Normal

  我必须查看代码，但仅从使用情况来看，它很可能是所有权重从 0 开始。这意味着当它开始训练时，您的超网络根本不会影响图像生成。这通常对神经网络训练来说是不好的，但在这种情况下，由于它是在另一个神经网络之上工作的注入神经网络，因此并不一定是不好的。==当基础模型已经创建了您要查找的内容并且您想要更微妙的更改时，您应该使用此选项==。这在使用真实照片时尤其正确，并且在这种情况下应该节省您的训练时间。但是，如果您想要创建一个影响每个生成的超网络，并带有样式更改（例如将艺术家样式应用于生成的每个图像），则这不是您想要的初始化，它将需要更长时间进行训练，并且可能不适用于每种情况。检查代码后，它是以非常小的噪声为中心为零。不适合 RELU。

  [stable-diffusion-webui/modules/hypernetworks/hypernetwork.py](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/d699720254365069866eafcdc519743664075a6d/modules/hypernetworks/hypernetwork.py#L76-L78)

  ```python
   if weight_init == "Normal" or type(layer) == torch.nn.LayerNorm: 
       normal_(w, mean=0.0, std=0.01) 
       normal_(b, mean=0.0, std=0.005) 

- Kaiming

  仅将其用于 RELU 样式的激活，因为权重都初始化为正。您还需要 normalization 才能有效地使用它。由于我不喜欢使用归一化（出于训练速度的原因），所以我没有进行足够的测试来告诉你什么时候应该真正使用它。它在技术上更适合深度网络，但超网络并没有那么深，所以。

- Xavier

  这是一个以 0 为中心的噪音。它对于 sigmoid/tanh 激活和某些 relu 混合函数很有用。对艺术超级网络特别有用，对现实生活中的图片不太有用。

## 激活























