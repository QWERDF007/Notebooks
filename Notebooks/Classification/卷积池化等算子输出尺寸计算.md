# 卷积、池化、反卷积、空洞卷积输出大小计算

参数定义：

- 输入图像大小： $h \times w$
- 卷积核大小： $k_h \times k_w$
- 填充大小： $p_h$ 和 $p_w$ 分别为行填充和列填充，上下分别填充 $p_h$，左右分别填充 $p_w$
- 步长： $s_h$ 和 $s_w$

## 卷积

- 输出高： $\large h_{out} = \lfloor (h - k_h + 2 \cdot p_h) / s_h  + 1 \rfloor$
- 输出宽： $\large w_{out} = \lfloor (w- k_w + 2 \cdot p_w) / s_w  + 1 \rfloor$
- 输出形状： $\large  \lfloor (h - k_h + 2 \cdot p_h) / S_h  + 1 \rfloor \times \lfloor (w - k_w + 2 \cdot p_w) / s_w  + 1 \rfloor$

```python
import troch
x = torch.randn(1, 3, 224, 224)
conv = torch.nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1)
print(x.shape)
print(conv(x).shape)
```

```shell
torch.Size([1, 3, 224, 224])
torch.Size([1, 64, 112, 112])
```

计算：

- $\large h_{out} = \lfloor (224 - 3 + 2 \cdot 1) / 2 + 1 \rfloor = \lfloor 112.5 \rfloor = 112$
- $\large w_{out} = \lfloor (224 - 3 + 2 \cdot 1) / 2 + 1 \rfloor = \lfloor 112.5 \rfloor = 112$

## 池化 (汇聚)

与卷积类似，只不过没有可学习的参数，而且一般不填充。

- 输出高： $\large h_{out} = \lfloor (h - k_h + 2 \cdot p_h) / s_h  + 1 \rfloor$
- 输出宽： $\large w_{out} = \lfloor (w- k_w + 2 \cdot p_w) / s_w  + 1 \rfloor$
- 输出形状： $\large  \lfloor (h - k_h + 2 \cdot p_h) / s_h  + 1 \rfloor \times \lfloor (w - k_w + 2 \cdot p_w) / s_w  + 1 \rfloor$

```python
x = torch.randn(1, 3, 224, 224)
pool2d = torch.nn.MaxPool2d(kernel_size=2, stride=2)
print(x.shape)
print(pool2d(x).shape)
```

```
torch.Size([1, 3, 224, 224])
torch.Size([1, 64, 112, 112])
```

计算：

- $\large h_{out} = \lfloor (224 - 2) / 2 + 1 \rfloor = \lfloor 112 \rfloor = 112$
- $\large w_{out} = \lfloor (224 - 2) / 2 + 1 \rfloor = \lfloor 112 \rfloor = 112$

## 反卷积 (转置卷积)





## 空洞卷积 (膨胀卷积)

空洞卷积的计算公式：
$$
\large \boldsymbol{y}[i] = \sum_k \boldsymbol{x}[i + r \cdot k] \boldsymbol{w}[k] \tag{1}
$$

空洞卷积的填充大小一般等于空洞率，即 $p = r$。

- 空洞率： $r_h$ 和 $r_w$
- 等效卷积核大小：
  - $\large k_h^{\prime} = k_h + (k_h -1) (r_h - 1)$ 
  - $\large k_w^{\prime} = k_w + (k_w -1) (r_w - 1)$ 
- 输出高： $\large h_{out} = \lfloor (h - k_h^{\prime} + 2 \cdot p_h) / s_h  + 1 \rfloor $
- 输出宽： $\large w_{out} = \lfloor (w- k_w^{\prime} + 2 \cdot p_w) / s_w  + 1 \rfloor$
- 输出形状： $\large  \lfloor (h - k_h^{\prime} + 2 \cdot p_h) / s_h  + 1 \rfloor \times \lfloor (w - k_w^{\prime} + 2 \cdot p_w) / s_w  + 1 \rfloor$

```
x = torch.randn(1, 3, 513, 513)
pool2d = torch.nn.torch.nn.Conv2d(3,64,kernel_size=3, stride=1, padding=2, dilation=2)
print(x.shape)
print(pool2d(x).shape)
```

```
torch.Size([1, 3, 513, 513])
torch.Size([1, 64, 513, 513])
```

计算：

- $\large k_h^{\prime} = 3 + (3 - 1)(2 - 1) = 3 + 2 \times 1 = 5$ 
- $\large k_w^{\prime} = 3 + (3 - 1)(2 - 1) = 3 + 2 \times 1 = 5$ 
- $\large h_{out} = \lfloor (513- 5 + 2 \times 2) / 1 + 1 \rfloor = \lfloor (513 - 5 + 4) / 1 + 1 \rfloor = 513$
- $\large w_{out} = \lfloor (513 - 5 + 2 \times 2) / 1 + 1 \rfloor = \lfloor (513 - 5 + 4) / 1 + 1 \rfloor = 513$
